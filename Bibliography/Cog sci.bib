Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Griffiths2007,
abstract = {Processing language requires the retrieval of concepts from memory in response to an ongoing stream of information. This retrieval is facilitated if one can infer the gist of a sentence, conversation, or document and use that gist to predict related concepts and disambiguate words. This article analyzes the abstract computational problem underlying the extraction and use of gist, formulating this problem as a rational statistical inference. This leads to a novel approach to semantic representation in which word meanings are represented in terms of a set of probabilistic topics. The topic model performs well in predicting word association and the effects of semantic association and ambiguity on a variety of language-processing and memory tasks. It also provides a foundation for developing more richly structured statistical models of language, as the generative process assumed in the topic model can easily be extended to incorporate other kinds of semantic and syntactic structure.},
author = {Griffiths, Thomas L. and Steyvers, Mark and Tenenbaum, Joshua B.},
doi = {10.1037/0033-295X.114.2.211},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Griffiths, Steyvers, Tenenbaum - 2007 - Topics in semantic representation(2).pdf:pdf},
isbn = {0033-295X (Print)$\backslash$r0033-295X (Linking)},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {bayesian models,compu-,probabilistic models,semantic memory,semantic representation},
number = {2},
pages = {211--244},
pmid = {17500626},
title = {{Topics in semantic representation.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.114.2.211},
volume = {114},
year = {2007}
}
@misc{Usher2001,
abstract = {The time course of perceptual choice is discussed in a model of gradual, leaky, stochastic, and competitive information accumulation in nonlinear decision units. Special cases of the model match a classical diffusion process, but leakage and competition work together to address several challenges to existing diffusion, random walk, and accumulator models. The model accounts for data from choice tasks using both time-controlled (e.g., response signal) and standard reaction time paradigms and its adequacy compares favorably with other approaches. A new paradigm that controls the time of arrival of information supporting different choice alternatives provides further support. The model captures choice behavior regardless of the number of alternatives, accounting for the log-linear relation between reaction time and number of alternatives (Hick's law) and explains a complex pattern of visual and contextual priming in visual word identification.},
author = {Usher, M and McClelland, J L},
booktitle = {Psychological review},
doi = {10.1037/0033-295X.108.3.550},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Usher, McClelland - 2001 - The time course of perceptual choice the leaky, competing accumulator model(2).pdf:pdf},
isbn = {0033-295X (Print)$\backslash$n0033-295X (Linking)},
issn = {0033-295X},
number = {3},
pages = {550--592},
pmid = {11488378},
title = {{The time course of perceptual choice: the leaky, competing accumulator model.}},
volume = {108},
year = {2001}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
author = {Ma, Wei Ji and Beck, Jeffrey M and Latham, Peter E and Pouget, Alexandre},
doi = {10.1038/nn1790},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2006 - Bayesian inference with probabilistic population codes(2).pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Algorithms,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Humans,Models,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurological,Normal Distribution,Poisson Distribution,Statistical},
number = {11},
pages = {1432--8},
pmid = {17057707},
title = {{Bayesian inference with probabilistic population codes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17057707},
volume = {9},
year = {2006}
}
@article{Marcus2013,
abstract = {An increasingly popular theory holds that the mind should be viewed as a near-optimal or rational engine of probabilistic inference, in domains as diverse as word learning, pragmatics, naive physics, and predictions of the future. We argue that this view, often identified with Bayesian models of inference, is markedly less promising than widely believed, and is undermined by post hoc practices that merit wholesale reevaluation. We also show that the common equation between probabilistic and rational or optimal is not justified.},
author = {Marcus, Gary F and Davis, Ernest},
doi = {10.1177/0956797613495418},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Marcus, Davis - 2013 - How robust are probabilistic models of higher-level cognition(2).pdf:pdf},
isbn = {0956-7976},
issn = {1467-9280},
journal = {Psychological science},
keywords = {13,27,8,bayesian models,be seen as an,cognition,engine of proba-,optimality,received 1,revision accepted 5,s,should the human mind},
number = {12},
pages = {2351--60},
pmid = {24084039},
title = {{How robust are probabilistic models of higher-level cognition?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24084039},
volume = {24},
year = {2013}
}
@article{Gershman2016,
abstract = {Computational models of reinforcement learning have played an important role in understanding learning and decision making behavior, as well as the neural mechanisms underlying these behaviors. However, fitting the parameters of these models can be challenging: the parameters are not identifiable, estimates are unreliable, and the fitted models may not have good predictive validity. Prior distributions on the parameters can help regularize estimates and to some extent deal with these challenges, but picking a good prior is itself challenging. This paper presents empirical priors for reinforcement learning models, showing that priors estimated from a relatively large dataset are more identifiable, more reliable, and have better predictive validity compared to model-fitting with uniform priors.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gershman, Samuel J.},
doi = {10.1016/j.jmp.2016.01.006},
eprint = {arXiv:1011.1669v3},
file = {:Users/Claudio/Desktop/Gershman16.pdf:pdf},
isbn = {0897916360},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Bayesian statistics,Model comparison,Parameter estimation,Q-learning},
pages = {1--6},
pmid = {261651700003},
publisher = {Elsevier Inc.},
title = {{Empirical priors for reinforcement learning models}},
url = {http://dx.doi.org/10.1016/j.jmp.2016.01.006},
volume = {71},
year = {2016}
}
@article{Knill2004,
abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are 'Bayes' optimal'. This leads to the 'Bayesian coding hypothesis': that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
author = {Knill, David C. and Pouget, Alexandre},
doi = {10.1016/j.tins.2004.10.007},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Knill, Pouget - 2004 - The Bayesian brain The role of uncertainty in neural coding and computation(2).pdf:pdf},
isbn = {0166-2236 (Print)$\backslash$n0166-2236 (Linking)},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {12},
pages = {712--719},
pmid = {15541511},
title = {{The Bayesian brain: The role of uncertainty in neural coding and computation}},
volume = {27},
year = {2004}
}
@article{Jazayeri2006,
abstract = {Sensory information is encoded by populations of neurons. The responses of individual neurons are inherently noisy, so the brain must interpret this information as reliably as possible. In most situations, the optimal strategy for decoding the population signal is to compute the likelihoods of the stimuli that are consistent with an observed neural response. But it has not been clear how the brain can directly compute likelihoods. Here we present a simple and biologically plausible model that can realize the likelihood function by computing a weighted sum of sensory neuron responses. The model provides the basis for an optimal decoding of sensory information. It explains a variety of psychophysical observations on detection, discrimination and identification, and it also directly predicts the relative contributions that different sensory neurons make to perceptual judgments.},
author = {Jazayeri, Mehrdad and Movshon, J Anthony},
doi = {10.1038/nn1691},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Jazayeri, Movshon - 2006 - Optimal representation of sensory information by neural populations(2).pdf:pdf},
isbn = {1097-6256 (Print)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature neuroscience},
number = {5},
pages = {690--696},
pmid = {16617339},
title = {{Optimal representation of sensory information by neural populations.}},
url = {http://www.nature.com/doifinder/10.1038/nn1691},
volume = {9},
year = {2006}
}
@article{Mitchell2008,
abstract = {The question of how the human brain represents conceptual knowledge has been debated in many scientific fields. Brain imaging studies have shown that different spatial patterns of neural activation are associated with thinking about different semantic categories of pictures and words (for example, tools, buildings, and animals). We present a computational model that predicts the functional magnetic resonance imaging (fMRI) neural activation associated with words for which fMRI data are not yet available. This model is trained with a combination of data from a trillion-word text corpus and observed fMRI data associated with viewing several dozen concrete nouns. Once trained, the model predicts fMRI activation for thousands of other concrete nouns in the text corpus, with highly significant accuracies over the 60 nouns for which we currently have fMRI data.},
author = {Mitchell, Tom M and Shinkareva, Svetlana V and Carlson, Andrew and Chang, Kai-Min M and Malave, Vicente L and Mason, Robert A and Just, Marcel Adam},
doi = {10.1126/science.1152876},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Mitchell et al. - 2008 - Predicting human brain activity associated with the meanings of nouns(3).pdf:pdf},
isbn = {1095-9203},
issn = {1095-9203},
journal = {Science},
number = {5880},
pages = {1191--5},
pmid = {18511683},
title = {{Predicting human brain activity associated with the meanings of nouns.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18511683{\%}5Cnd:/pdf/Mitchell et al 2008 Science.pdf},
volume = {320},
year = {2008}
}
@article{Ratcliff2008,
abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data-accuracy, mean response times, and response time distributions-into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ratcliff, Roger and McKoon, Gail},
doi = {10.1162/neco.2008.12-06-420},
eprint = {NIHMS150003},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Ratcliff, McKoon - 2008 - The diffusion decision model theory and data for two-choice decision tasks(2).pdf:pdf},
isbn = {0899-7667 (Print)$\backslash$n0899-7667 (Linking)},
issn = {0899-7667},
journal = {Neural computation},
number = {4},
pages = {873--922},
pmid = {18085991},
title = {{The diffusion decision model: theory and data for two-choice decision tasks.}},
volume = {20},
year = {2008}
}
@article{Jones2011,
abstract = {The prominence of Bayesian modeling of cognition has increased recently largely because of mathematical advances in specifying and deriving predictions from complex probabilistic models. Much of this research aims to demonstrate that cognitive behavior can be explained from rational principles alone, without recourse to psychological or neurological processes and representations. We note commonalities between this rational approach and other movements in psychology - namely, Behaviorism and evolutionary psychology - that set aside mechanistic explanations or make use of optimality assumptions. Through these comparisons, we identify a number of challenges that limit the rational program's potential contribution to psychological theory. Specifically, rational Bayesian models are significantly unconstrained, both because they are uninformed by a wide range of process-level data and because their assumptions about the environment are generally not grounded in empirical measurement. The psychological implications of most Bayesian models are also unclear. Bayesian inference itself is conceptually trivial, but strong assumptions are often embedded in the hypothesis sets and the approximation algorithms used to derive model predictions, without a clear delineation between psychological commitments and implementational details. Comparing multiple Bayesian models of the same task is rare, as is the realization that many Bayesian models recapitulate existing (mechanistic level) theories. Despite the expressive power of current Bayesian models, we argue they must be developed in conjunction with mechanistic considerations to offer substantive explanations of cognition. We lay out several means for such an integration, which take into account the representations on which Bayesian inference operates, as well as the algorithms and heuristics that carry it out. We argue this unification will better facilitate lasting contributions to psychological theory, avoiding the pitfalls that have plagued previous theoretical movements.},
author = {Jones, Matt and Love, Bradley C},
doi = {10.1017/S0140525X10003134},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Jones, Love - 2011 - Bayesian fundamentalism or enlightenment On the explanatory status and theoretical contributions of Bayesian mod(2).pdf:pdf},
isbn = {1469-1825 (Electronic)$\backslash$n0140-525X (Linking)},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {bayesian modeling,cognitive processing,levels of analysis,rational analysis,representation},
number = {4},
pages = {169--188},
pmid = {21864419},
title = {{Bayesian fundamentalism or enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition.}},
volume = {34},
year = {2011}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/LeCun, Bengio, Hinton - 2015 - Deep learning(2).pdf:pdf},
isbn = {9780521835688},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {10463930},
title = {{Deep learning}},
url = {http://dx.doi.org/10.1038/nature14539},
volume = {521},
year = {2015}
}
@article{Fahnn1987,
author = {Fahnn, Scoff E and Hinton, Geoffrey E},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Fahnn, Hinton - 1987 - Connectionist Architectures for Artificial Intelligence Massively parallel networks of simple aspects of intel(2).pdf:pdf},
title = {{Connectionist Architectures for Artificial Intelligence Massively parallel networks of simple aspects of intelligence not captured by existing AI technology on serial machines . What is connectionism ?}},
year = {1987}
}
@article{Graves2016,
abstract = {Modern computers separate computation and memory. Computation is performed by a processor, which can use an addressable memory to bring operands in and out of play. This confers two important benefits: the use of extensible storage to write new information and the ability to treat the contents of memory as variables. Variables are critical to algorithm generality: to perform the same procedure on one datum or another, an algorithm merely has to change the address it reads from. In contrast to computers, the computational and memory resources of artificial neural networks are mixed together in the network weights and neuron activity. This is a major liability: as the memory demands of a task increase, these networks cannot allocate new storage dynam-ically, nor easily learn algorithms that act independently of the values realized by the task variables. Although recent breakthroughs demonstrate that neural networks are remarkably adept at sensory processing 1 , sequence learning 2,3 and reinforcement learning 4 , cognitive scientists and neuroscientists have argued that neural networks are limited in their ability to represent variables and data structures 5–9 , and to store data over long timescales without interference 10,11 . We aim to combine the advantages of neu-ral and computational processing by providing a neural network with read–write access to external memory. The access is narrowly focused, minimizing interference among memoranda and enabling long-term storage 12,13 . The whole system is differentiable, and can therefore be trained end-to-end with gradient descent, allowing the network to learn how to operate and organize the memory in a goal-directed manner.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.5401v2},
author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'{n}}ska, Agnieszka and {G{\'{o}}mez Colmenarejo}, Sergio and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and {Moritz Hermann}, Karl and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
doi = {10.1038/nature20101},
eprint = {arXiv:1410.5401v2},
isbn = {0896-6273},
issn = {0028-0836},
journal = {Nature Publishing Group},
number = {7626},
pages = {471--476},
pmid = {26774160},
title = {{Hybrid computing using a neural network with dynamic external memory}},
url = {http://dx.doi.org/10.1038/nature20101},
volume = {538},
year = {2016}
}
@article{Montague1999,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Montague, P.Read},
doi = {10.1016/S1364-6613(99)01331-5},
eprint = {1603.02199},
file = {:Users/Claudio/Library/Application Support/Mendeley Desktop/Downloaded/Montague - 1999 - Reinforcement Learning An Introduction, by Sutton, R.S. and Barto, A.G.pdf:pdf},
isbn = {0262193981},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {9},
pages = {360},
pmid = {18255791},
title = {{Reinforcement Learning: An Introduction, by Sutton, R.S. and Barto, A.G.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661399013315},
volume = {3},
year = {1999}
}
@article{Gallistel2000,
abstract = {Associative theories of learning assume a general-purpose learning process whose structure does not reflect the demands of a particular learning problem. By contrast, implicit in the studies of learning conducted by zoologists and, recently, by some experimental psychologists, is the assumption that learning mechanisms are specialiyed computationally for solving particular kinds of problemns. Models of the latter kind have begun to be applied even to the results from experiments on classical and instrumental conditioning. These models imply that to understand learning neurobiologically, we must discover the cellular mechanisms by which the nervous system stores and retrieves the values of variables and carries out the elementary computational operations (the elementary operations of arithmetic and logic). At the systems level, we must discover the circuits that implement special-purpose computations using these universal elements of computation.},
author = {Gallistel, C. Randy},
isbn = {0-471-33170-8},
journal = {The new cognitive neurosciences},
pages = {1179--1191},
title = {{The replacement of general-purpose learning models with adaptively specialized learning modules}},
url = {http://www.lscp.net/persons/dupoux/teaching/QUINZAINE{\_}RENTREE{\_}CogMaster{\_}2006-07/Bloc1{\_}philo/Preprint{\_}replacement{\_}of{\_}general{\_}pupose{\_}readiing.pdf},
year = {2000}
}
@article{Huth2016,
abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system'. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods—commonplace in studies of human neuroanatomy and functional connectivity—provide a powerful and efficient means for mapping functional representations in the brain.},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Huth, Alexander G and Heer, Wendy A De and Griffiths, Thomas L and Theunissen, Fr{\'{e}}d{\'{e}}ric E and Jack, L},
doi = {10.1038/nature17637},
eprint = {arXiv:1408.1149},
isbn = {0008-5472 (Print)$\backslash$r0008-5472 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7600},
pages = {453--458},
pmid = {27121839},
publisher = {Nature Publishing Group},
title = {{Natural speech reveals the semantic maps that tile human cerebral cortex}},
url = {http://dx.doi.org/10.1038/nature17637},
volume = {532},
year = {2016}
}
