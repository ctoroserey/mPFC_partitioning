---
title: 'Individual heterogeneity in the functional network topography of medial prefrontal cortex'
author: "Claudio Toro-Serey^1^, Sean M. Tobyne^2^, & Joseph T. McGuire^1^"
output:
  pdf_document: 
    keep_tex: false
    highlight: haddock
bibliography: mPFC_paper.bib
csl: apa.csl
header-includes:
    - \usepackage{setspace}\doublespacing
    - \usepackage[left]{lineno}
    - \linenumbers
    - \usepackage{float}
    - \newcommand{\beginsupplement}{ 
        \setcounter{table}{0}  
        \renewcommand{\thetable}{S\arabic{table}} 
        \setcounter{figure}{0} 
        \renewcommand{\thefigure}{S\arabic{figure}}
      }

---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, fig.pos = 'H')
```

```{r Libraries, functions, and setups, include = FALSE, echo = FALSE}

# color scheme
Cols <- c("aquamarine4", "#D9541A", rgb(190, 190, 190, 100, maxColorValue = 255)) 

# In case I want to visualize stuff in the brain
labelCoords_vertex <- read.csv2('labelCoords_vertex.csv', sep = ",")[, 2:6]
labelCoords_vertex <- transform(labelCoords_vertex, 
                                x = as.numeric(as.character(x)), 
                                y = as.numeric(as.character(y)), 
                                z = as.numeric(as.character(z)))

# general options
threshMaps <- TRUE # Whether to apply subject-wise thresholds on maps or not
Permute <- FALSE # show meta-analysis permutation progress? (SLOW)

# Libraries used for the whole process
library(tidyverse)
library(ggplot2)
library(data.table) 
library(mcclust) 
library(lme4)
library(parallel) 
library(corrplot)
library(DescTools)
library(knitr)


## produce one permutation instance of the meta-analysis (so it can be fed to mclapply for faster results)
metaPerm <- function(list1 = studyList_sv, list2 = studyList_DN, labels = Yeo_labels, perm = 1) {
  
  # print every 100th permutation just to have a general sense of how far we are
  if ((perm %% 100) == 0) {sprintf("Permutation %s", perm)}
  
  # combine study lists
  allStudies <- c(studyList_sv, studyList_DN)
  
  # Sample all the studies and divide into 2 groups
  randPerm <- sample(allStudies)
  tmpSV <- randPerm[seq(length(list1))]
  tmpDN <- randPerm[-seq(length(list1))]
  
  # Count the number of times each region was reported in the literature
  tmpDF <- data.frame(Parcel = gsub("_", "", labels),
                      SV = sapply(labels, function(roi) {length(grep(roi, tmpSV))}),
                      DN = sapply(labels, function(roi) {length(grep(roi, tmpDN))}))
  
  # Perform the prop test for each pair and get the max chi-squared stat
  maxStat <- max(
    apply(tmpDF[, 2:3], 1, function(data) {
      prop.test(data, c(length(tmpSV), length(tmpDN)))$statistic
    }
    ), na.rm = T)
  
  return(maxStat)
  
}


## Cohen's D for 2 groups
# for a more flexible approach, make the data input to be a list with entries for n groups, 
# then do length(list) for the number of groups. 
cohenD <- function(group1 = 1, group2 = 2){
  
  # means
  mean1 <- mean(group1, na.rm = T)
  mean2 <- mean(group2, na.rm = T)
  
  # variance
  var1 <- var(group1, na.rm = T)
  var2 <- var(group2, na.rm = T)
  
  # equation
  out <- (mean1 - mean2) / sqrt((var1 + var2)/2)
  
  return(out)
  
}


## get ROI coords & index
# The point here is to reduce the summary dframes from community detection to show only ROIs
# Should work for extracting any label-indexed dframe though
# I wanted to also get the index in case I want to extract specific rows from parcel/vertex coord dframes
getCoords <- function(Labels = DN_labels, Coords = labelCoords_parcel, TimeSeries = FALSE){
  
  indx <- numeric()
  
  # If you want to select time series from raw data
  if (TimeSeries == TRUE) {
    
    for (ROI in Labels) {
      indx <- c(indx, grep(ROI, rownames(Coords)))
    }
    
  } else { # for the summary output of the community detection output
    
    for (ROI in Labels) {
      indx <- c(indx, grep(ROI, Coords$Label))
    }
    
  }
  
  results <- list()
  results$Index <- indx
  results$Coords <- Coords[indx, ]
  
  return(results)
  
}


## Permutation for 2 groups
permute <- function(group1 = 1, group2 = 2, statType = mean, nPerms = 5000, paired = FALSE){
  
  # prep data
  summaryPerm <- list()
  lOne <- length(group1)
  lTwo <- length(group2)
  bigSample <- c(group1,group2)  
  
  if (paired == FALSE) {
    
    
    for (i in 1:nPerms){
      
      # relabel samples
      tempBig <- sample(bigSample)
      tempOne <- tempBig[seq(lOne)]
      tempTwo <- tempBig[-seq(lOne)]
      
      # stats
      tempDiffs <- statType(tempOne,na.rm=T) - statType(tempTwo,na.rm=T)
      summaryPerm$jointDist[i] <- tempDiffs # statType(tempDiffs, na.rm = T) 
      
    }  
    
  } else {
    
    for (i in 1:nPerms){
      
      # shift labels in a pairwise fashion
      tempDiffs <- statType((-1)^rbinom(lOne,1,0.5) * (group1 - group2))
      summaryPerm$jointDist[i] <- tempDiffs
      
    }
    
  }
  
  # get the observed difference
  diffs <- statType(group1,na.rm=T) - statType(group2,na.rm=T)
  observedAbs <- abs(diffs) # maybe leave it as means here
  observed <- diffs
  summaryPerm$Pval <- 2 * (1 - ecdf(summaryPerm$jointDist)(observedAbs))
  if (length(unique(abs(summaryPerm$jointDist))) == 1) {summaryPerm$Pval <- 1} # if the difference is always the same, then p = 1
  summaryPerm$Observed <- observed
  
  return(summaryPerm)
  
}


## Non-parametric Bootstrap for a single group
bootstrap <- function(group = 1, statType = mean, B = 5000){
  
  # prep param
  bootStats <- rep(0,B)
  
  # iterate
  for(b in 1:B){
    
    # wait group
    x <- sample(group,length(group),replace=T)  
    bootStats[b] <- statType(x,na.rm = T)
    
  }
  
  return(bootStats)
  
}


# Create a vector ready to be used for HCP data (32k CIFTI surface)
# The input should be the summary from community partitioning
# Once this is created, go to the terminal and input something like this
# wb_command -cifti-convert -from-text dataforCifti.txt testSubj.dscalar.nii testCifti.dscalar.nii
# testSubj can be found under the `Basic_files` in the repo
HCPOut <- function(Data = DNval7mCommunities[[1]], MOI = "Membership", SubjID = "100307", padding = 0){
  
  nVertices <- 59412
  tempVec <- rep(padding, nVertices)
  temp <- grep(MOI, colnames(Data))
  tempVec[Data$Vertex] <- Data[[temp]]
  write.table(file = paste(SubjID,"_",MOI,'_dataforCifti.txt', sep=""), tempVec, row.names = F, col.names = F, dec = ".")
  
}


# Perform pairwise comparisons of clustering outcomes on all subjects
comparePartitions <- function(Data = DNval7mCommunities, MOI = "FiedlerBinary", Index = "VI", nSubjects = nSubj, subjNames = subjList) {
  # This function will compare the community partitions from all subjects and create a 'comparison matrix' for every pairwise combination of subjects
  # Alternatively, if a second MOI is added 
  # Inputs
  # 
  # Data: the list of summaries produced by the script
  # 
  # MOI: measure of interest (usually the binarized Fiedler vector). If a vector, compares across algorithms per subject
  # 
  # Index: VI for variation of information, RI for the adjusted rand index, Cor for a Pearson correlation
  # ARI can yield many decimals, thus inflating the ratios. I thus round at 4 decimals.
  
  # NOTES:
  # you can apply pairwise comparisons with outer: outer(tempList,tempList,FUN = Vectorize(arandi, SIMPLIFY = FALSE, USE.NAMES = FALSE))
  
  # Get the column position of the MOI(s)
  Columns <- colnames(Data[[1]])
  indx <- as.numeric(Columns %in% MOI)
  MOI_indx <- which(indx==1)
  
  if (length(MOI_indx) < 2) {
    # Combine the measures of interest
    allVecs <- do.call(cbind, lapply(Data, "[[", MOI))
    
    # Create empty matrix
    indexMatrix <- matrix(data = NA, nrow = nSubjects, ncol = nSubjects)
    dimnames(indexMatrix) <- list(subjNames, subjNames)
    
    # Run every pairwise comparison with the index of interest on the measure of interest
    if (Index == "VI") {
      for (subj in seq(nSubjects)) {
        for (subj2 in seq(nSubjects)) {
          indexMatrix[subj, subj2] <- vi.dist(allVecs[, subj], allVecs[, subj2])
        }
      }
    } else if (Index == "RI") {
      for (subj in seq(nSubjects)) {
        for (subj2 in seq(nSubjects)) {
          indexMatrix[subj, subj2] <- arandi(allVecs[, subj], allVecs[, subj2], adjust = T)
        }
      }
    } else if (Index == "Cor") {
      for (subj in seq(nSubjects)) {
        for (subj2 in seq(nSubjects)) {
          indexMatrix[subj, subj2] <- cor(allVecs[, subj], allVecs[, subj2], method = "spearman")
        }
      }
    }
    
    indexMatrix <- round(indexMatrix, digits = 4)
    
  } else {
    indexMatrix <- data.frame(SubjID = as.character(subjList),
                              Index = rep(0, nSubjects))
    # Run every pairwise comparison with the index of interest on the measure of interest
    if (Index == "VI") {
      for (subj in seq(nSubjects)) {
        indexMatrix$Index[subj] <- vi.dist(Data[[subj]][, MOI_indx[1]], Data[[subj]][, MOI_indx[2]])
      }
    } else if (Index == "RI") {
      for (subj in seq(nSubjects)) {
        indexMatrix$Index[subj] <- arandi(Data[[subj]][, MOI_indx[1]], Data[[subj]][, MOI_indx[2]], adjust = T)
      }
    } else if (Index == "Cor") {
      for (subj in seq(nSubjects)) {
        indexMatrix$Index[subj] <- cor(Data[[subj]][, MOI_indx[1]], Data[[subj]][, MOI_indx[2]], method = "spearman")
      }
    }
    
    indexMatrix$Index <- round(indexMatrix$Index, digits = 4)
  
  }
  
  return(indexMatrix) 
  
}


# Generate a matrix with submatrices of 1s of a given size along the diagonal
# Useful to extract specific portions of data from a similarity matrix
diagBlocks <- function(dims = 20, sqSize = 4) {
  div <- dims %/% sqSize
  finalMatrix<-matrix(0,nrow=dims,ncol=dims)
  index <- 1
  for(k in seq(div)){
    finalMatrix[index:(index + (sqSize-1)),index:(index + (sqSize-1))] <- 1
    index<-index + sqSize
  }
  finalMatrix <- finalMatrix == 1
  finalMatrix
}


# This function will select a two-tailed fiedler vector threshold with respect to the stability of the vertex
# The threshold will be based on proportion DN given by thresholdRange
threshFV <- function(Data, thresholdRange = c(0.01, 0.99), nthresh = 50) {

  ## Check if the proportions even go that low, otherwise replace by next most stable low/high value
  # get the 2 values with highest reports (this should be stable upper/lower proportions)
  stableExtremes <- sort(table(Data$slidePropDN), decreasing = T)[seq(2)]
  stableExtremes <- sort(as.numeric(names(stableExtremes)))
  
  
  # if the values are not extreme enough, replace the original threshold with the new stable ones
  if (thresholdRange[1] < stableExtremes[1]) {
    
    thresholdRange[1] <- stableExtremes[1]
    
  }
  
  if (thresholdRange[2] > stableExtremes[2]) {
    
    thresholdRange[2] <- stableExtremes[2]
    
  }
  
  ## Run the actual process
  # placeholder to be returned
  thresholds <- c(NA,NA)
  
  
  # start the counter at chance
  meanProp <- 0.5
  
  
  # select a range of FV values
  thresh <- seq(0, min(Data$FiedlerVec), length.out = nthresh)
  
  
  # Iterate over the possible FV until DN affiliations go below 1%
  count <- 1
  while (meanProp >= thresholdRange[1]) {
    
    # get the mean proportion of DN from remaining vertices based on putative threshold
    meanProp <- Data %>% filter(FiedlerVec <= thresh[count]) %>% summarize(mean(slidePropDN))
    
    # if a threshold meets requirement, store its value
    if (meanProp <= thresholdRange[1]) {
      thresholds[1] <- thresh[count]
    }

    count <- count + 1
    
  }
  
  
  # repeat for the upper threshold
  # restart parameters
  meanProp <- 0.5
  thresh <- seq(0, max(abs(Data$FiedlerVec)), length.out = nthresh)
  
  
  # Iterate over the possible FV until DN affiliations go over 99%
  count <- 1
  while (meanProp <= thresholdRange[2]) {
    
    # get the mean proportion of DN from remaining vertices based on putative threshold
    meanProp <- Data %>% filter(FiedlerVec > thresh[count]) %>% summarize(mean(slidePropDN))
    
    # if a threshold meets requirement, store its value
    if (meanProp >= thresholdRange[2]) {
      thresholds[2] <- thresh[count]
    }

    count <- count + 1
    
  }
  
  
  return(round(thresholds, digits = 5))

  
}
```

1.  Department of Psychological and Brain Sciences, Boston University, Boston, USA

2.  Graduate Program for Neuroscience, Boston University, Boston, USA

Corresponding author: Claudio Toro-Serey (ctoro@bu.edu)

\newpage

## Abstract 

  Human medial prefrontal cortex (mPFC) and posterior cingulate cortex (PCC) are implicated in multiple cognitive functions, including subjective valuation processes and processes linked to the default network (DN). Our ability to interpret these seemingly co-localized effects is constrained by a limited understanding of the individual-level heterogeneity in mPFC/PCC functional organization. Here we used cortical surface-based meta-analysis to identify a parcel in human PCC that was preferentially implicated in DN effects relative to valuation. We then used resting-state fMRI data and a data-driven network analysis algorithm, spectral partitioning, to partition mPFC and PCC into "DN" and "non-DN" subdivisions in individual participants (n = 100 from the Human Connectome Project). The spectral partitioning algorithm efficiently identified individual-level cortical subdivisions that were reliable across test/retest sessions and varied markedly across individuals, especially in mPFC. Our results point toward a new generation of strategies for assessing whether distinct cognitive functions engage common or distinct mPFC subregions. 

**Keywords:** brain networks; DN; individual differences

\newpage

## Introduction

  Human medial prefrontal cortex (mPFC) and posterior cingulate cortex (PCC) are jointly associated with a large and diverse set of cognitive functions [@Hiser2018; @Kragel2018]. One such function is subjective valuation during economic decision making. Both mPFC and PCC (together with ventral striatum) consistently show greater BOLD activity in response to more highly valued choice prospects and outcomes, relative to prospects and outcomes that are less highly valued [@Bartra2013; @Clithero2014; @Hiser2018; @Kable2007; @Levy2011]. Both mPFC and PCC are also among the regions implicated in a set of functions associated with the default network (DN). DN effects include a decrease in BOLD activity during cognitively demanding tasks compared with less-demanding task conditions or periods of rest [@Mckiernan2003; @Laird2009], as well as a distinctive pattern of inter-region correlations in resting-state fMRI data [@Greicius2003; @Fox2005; @Yeo2011].

  Coordinate-based meta-analyses of the fMRI literature show that valuation and DN effects occur in overlapping and largely indistinguishable regions of ventral mPFC [@Acikalin2017]. The two sets of effects diverge in other brain areas; a region of the striatum is preferentially associated with valuation, whereas bilateral temporoparietal junction is linked with the DN. Within PCC and adjacent precuneus, a more posterior subregion appears DN-specific, whereas a more anterior subregion is implicated in both effects. One possible interpretation of these findings is that mPFC and anterior PCC operate as common nodes within partially overlapping distributed brain systems that subserve valuation and DN effects. This colocalization has prompted theories that valuation and DN-related processes share common elements at the psychological level. For example, the two sets of processes might share elements of self-referential cognition, episodic memory, mental simulation, or monitoring and regulation of internal states [@Acikalin2017; @Clithero2014; @Northoff2012; @Reddan2018].
  
  However, strong conclusions about functional colocalization require consideration of individual-level heterogeneity in topographic patterns of brain activity. A recognized limitation of group averaging and meta-analysis is that the functional topography of individual brains can be misaligned and blurred [@Fedorenko2012; @Guntupalli2018a; @Michalka2015; @Tobyne2018; @Wang2015; @Woo2014], exaggerating the apparent overlap across domains. This concern is especially pronounced in mPFC, which is subject to considerable idiosyncratic cortical folding [@Lopez2019; @Mackey2014; @Zilles2013] and inter-subject functional variability [@Mueller2013]. An alternative approach is to focus on analyses at the individual-participant level. Individual-level analyses of fMRI data have identified idiosyncratic, reliable, and valid patterns of functional organization that would be blurred in aggregative estimates [@Gordon2017; @Gratton2018b; @Laumann2015; @Tobyne2018], and subject-specific network arrangements have been found to predict behavioral characteristics [@Kong2018]. Recent work has uncovered fine-grained subdivisions within the DN using both data-driven clustering and individually customized seed-based connectivity analysis [@Braga2017; @Braga2019]. It is therefore possible that the previously reported overlap of DN and valuation effects can be attributed to low effective spatial resolution, and that the organization of mPFC and PCC would be better understood at the individual level. An important first step, and the goal of the present paper, is to quantify the degree of topographic heterogeneity of DN effects within mPFC and PCC in a large sample of individuals. This initial evaluation of variability during rest will provide grounds for individualized topographical estimation of behavioral effects (such as valuation) in the future.

  A useful way to characterize individual-specific brain organization is to examine patterns of resting-state functional connectivity. Connectome-based analyses of resting-state functional connectivity have been fruitful in identifying individualized functional subregions that correspond well to task-induced activity patterns [@Gordon2017; @Laumann2015; @Smith2009; @Tobyne2018]. A functional connectome can be represented in the form of a network, and graph theoretic methods can be applied to analyze the network's structure [@Bassett2017; @Rubinov2010]. In the context of network analysis, community detection algorithms subdivide brain networks into sets of nodes that share more connections with each other than with the rest of the network [@Fortunato2016; @Garcia2017]. Here we use the technique of spectral partitioning (SP), an efficient community detection algorithm that deterministically subdivides a network into two communities [@Belkin2003; @chung1997; @Fiedler1975]. SP has previously been used to characterize the posterior-anterior functional gradient of the insula using resting-state fMRI data [@Tian2018], and was shown to robustly and reliably separate both simulated and actual primate ECoG networks [@Toker2019]. We use SP here to identify subsets of nodes within mPFC and PCC that share spontaneously covarying temporal activation patterns during rest.

  In this study, we aimed to subdivide mPFC and PCC into individual-specific DN and non-DN communities, and to quantify the degree of topographic heterogeneity in the resulting community structure over time and across individuals. We did this by capitalizing on the respective strengths of meta-analysis and subject-specific analyses of brain networks. We used a data-driven procedure to identify two communities that each spanned both mPFC and PCC in each individual participant. We found that the resulting communities had a consistent topographic layout within PCC (according to a label-agnostic similarity metric), whereas their layout in mPFC was individual-specific and stable across test/re-test. We took advantage of the more consistent configuration within PCC to assign meta-analysis-derived labels to the two communities. Because our data-driven method established correspondence between PCC subregions and mPFC subregions, the labels defined in PCC could then be indexed into the more heterogeneous community structure of mPFC in each individual.
  
  The outline of our paper is as follows. First, we established a search space by selecting parcels from an established brain atlas [@Glasser2016] that corresponded to previously defined DN and limbic networks on the medial cortical wall [@Yeo2011]. A cortical surface-based meta-analysis of the DN and valuation literatures identified a parcel in PCC that was DN-specific at the aggregate level. We then derived a functional connectivity network of all the surface vertices within the search space for each of `r length(dir(path = './Summary'))` individual resting-state fMRI data sets from the Human Connectome Project [HCP; @VanEssen2012], and used the SP algorithm to subdivide each individual's network into DN and non-DN communities (labeled according to which community included the meta-analytically identified DN-specific parcel in PCC). Focusing on individual vertices in the search space rather than the parcels (as is typical in brain network analyses) allowed us to finely delineate the topographic extent of each community. The resulting communities varied topographically across individuals, while also appearing to follow common organizational principles. Sliding window and test-retest analyses showed that these partitionings were highly similar across scanning days within (but not between) individuals, and that individual-level idiosyncrasy was greater in mPFC. Partitionings obtained from the SP algorithm had higher test-retest reliability than did analogous results from seed-based functional connectivity. Lastly, we describe how the structure of the resulting automatically defined DN and non-DN communities both aligns with and differs from recently proposed scheme for identifying subdivisions within the DN [@Braga2017; @Braga2019]. Our work highlights the usefulness of estimating brain effects at the individual level in mPFC and PCC, and provides a new framework and tool set for future investigations of overlap across cognitive domains.

## Methods

All code used in this study is openly available at [https://github.com/ctoroserey/mPFC_partitioning](https://github.com/ctoroserey/mPFC_partitioning)

### *Search space*

For all analyses, we defined our search space based on the 17-network parcellation proposed by Yeo et al. [-@Yeo2011]. First, we selected vertices on the medial cortical surface that were contained by the DN and limbic networks in HCP's 32,000 vertex surface space (fs_LR_32k). Next, we overlaid those networks on a parcellated atlas of the human cortical surface [360 regions; @Glasser2016], and retained a set of parcels that covered approximately the same brain regions. This resulted in a search space that consisted of 40 parcels across hemispheres (Supplementary Table 1). The search space in each hemisphere was naturally divided into two spatially non-contiguous clusters in PCC and mPFC, facilitating the examination of each region separately.

\bigskip

### *Meta-analysis*

We used a novel approach to cortical surface parcel-based meta-analysis to assess whether individual parcels within the search space were preferentially associated with valuation or DN effects. For subjective valuation, we gathered peak activation coordinates from 200 studies that were associated with positive effects in contrasts of higher-value minus lower-value outcomes or prospects [@Bartra2013]. For DN, we acquired coordinates from 80 studies that were related to task-deactivation [@Laird2009]. The coordinates represent areas that exceeded the statistical significance threshold in each original study. For each study, we created an indicator map in standard volumetric space (MNI152, 1 mm resolution) which contained values of 1 in a 10 mm radius sphere around each reported activation peak, and values of 0 elsewhere [@Wager2009]. The indicator map for each study was then projected to a standard cortical mesh (fsaverage, 160,000 vertices, projfrac-max from 0 to 1 by 0.25, registered using mni152.register.dat) using FreeSurfer's mri_vol2surf [@Fischl1999; @Dale1999] (http://surfer.nmr.mgh.harvard.edu/). We then resampled the Glasser et al. (2016) parcellation to fsaverage, and tallied how many studies had positive indicator values intersecting with each cortical parcel (the details of the resampling procedure are described in https://wiki.humanconnectome.org/display/PublicData/HCP+Users+FAQ#HCPUsersFAQ-9.HowdoImapdatabetweenFreeSurferandHCP, and were implemented using a custom script available at https://github.com/stobyne/Spherical-Surface-Swapper). Two studies from the subjective valuation corpus were removed because they did not contain activation peaks that overlapped with cortex, leaving a final number of 198 studies. 

To test for parcels that were significantly more strongly associated with one domain than the other, we performed per-parcel chi-squared tests comparing the proportion of studies with activation in that parcel between the two domains. We permuted the study domain labels (DN or valuation) 5000 times while preserving the total number of studies in each domain, and on each iteration stored the maximum resulting chi-squared statistic across all parcels. This gave us a null distribution of 5000 maximum chi-squared values. The 95th percentile of this distribution served as an FWE-corrected significance threshold to evaluate unpermuted chi-squared values.   

### *Resting-state fMRI Data*

``` {r fMRI data descriptives} 
# load file with the n of TRs and density data
corrCounts <- read.csv('corrCounts.csv')
```

Our fMRI analyses used resting-state fMRI data from the Human Connectome Project [@VanEssen2012] Q6 release (N = `r length(dir(path = './Summary'))`, randomly sampled from the total pool of 469 available subjects). Each subject's data was acquired over two days at Washington University in St. Louis on a Siemens CONNECTOM Skyra MRI scanner (Siemens, Erlangen, Germany). Four resting state runs (repetition time = 0.720 s, echo time = 33.1 ms, flip angle = 52°, multiband factor = 8, 72 slices, 2 mm isotropic voxels) each comprised 1200 time points (14 min 24 s) for a total of 4800 time points. Two runs were acquired on each day, with the phase encoding direction set to left-right for one run and right-left for the other. Only subjects with both left-right and right-left phase encoding for each day were included (i.e. subjects with four resting-state fMRI sessions). In addition, only datasets with low motion levels (under 1.5 mm) and less than 5% of points over 0.5 mm framewise displacement (FD) were used. See [@VanEssen2012] for more details about the data acquisition protocol.

Data initially underwent the HCP minimal preprocessing pipeline [@Glasser2013], which included gradient nonlinearity correction, motion correction, EPI distortion correction, high-pass filtering (0.0005 Hz threshold), MNI152-based normalization, surface reconstruction, and mapping of functional data to a standardized cortical surface model (details can be found in Glasser et al., 2013). In addition, data underwent temporal denoising based on independent components [FMRIB's ICA-based X-noiseifier, FIX; @Griffanti2014; @Salimi-Khorshidi2014]. Data were further preprocessed using an in-house pipeline described previously [@Tobyne2017]. Steps (in order) included linear interpolation across high motion timepoints with over 0.5 mm of framewise displacement, band-pass filtering (allowed frequencies ranged from 0.009 and 0.08 Hz), and temporal denoising via mean grayordinate signal regression [@Burgess2016]. After filtering and denoising, the interpolated high-motion time points were censored by deletion and each run was temporally de-meaned. The processed time series had a median of `r median(corrCounts$nTR)` time points (minimum = `r min(corrCounts$nTR)`) across participants. Each subject's brain was comprised of 32k standard grayordinates per hemisphere (combined in a CIFTI file). We retained only the cortical surfaces, which resulted in 59,412 total surface vertices per subject. 

### *Network Definition*

```{r Density calculation}
# Load density data
corrCounts <- corrCounts %>%
  mutate(prcntNS = NonSignificant / Total,
         prcntPos = SignificantPos / (Total - NonSignificant),
         prcntNeg = SignificantNeg / (Total - NonSignificant),
         density = 1 - prcntNS)

# density descriptives
mdAll <- mean(corrCounts$density)
sddAll <- sd(corrCounts$density)

# prcnt pos/neg
mPos <- round(mean(corrCounts$prcntPos), digits = 2)
sdPos <-round(sd(corrCounts$prcntPos), digits = 2)
mNeg <- round(mean(corrCounts$prcntNeg), digits = 2)
sdNeg <-round(sd(corrCounts$prcntNeg), digits = 2)
```

All network analyses were performed using the igraph package [v. 1.1.2; https://igraph.org/r/; @G.2006] in R [v. 3.4.1; https://www.r-project.org/; @RTeam2018]. To establish each subject's network, we selected all the vertices contained within the mPFC/PCC search space (n = 4,801 per subject; mPFC = 2854, PCC = 1947) and computed the Pearson correlation of the time series for every pair of vertices. This produced a weighted network for each subject, in which the nodes were surface vertices and the edges were the correlations among them. Next, we applied Fisher's r to z transformation, and performed a two-sided significance test to identify significant connections. The resulting p-values were corrected for multiple comparisons (FDR < 0.05), and edges with non-significant correlations were set to 0 (all other edges retained their respective z-values). The proportion of remaining edges (i.e. network density) was high for all individuals (mean = `r round(mdAll, digits = 2)`, SD = `r round(sddAll, digits = 3)`), and the retained edges mostly consisted of positive correlations (mean proportion positive = `r mPos`, sd = `r sdPos`). Next, we took the exponential of these values so that all weights were positive while maintaining the ordinal ranks of the original correlation distribution within the set of retained edges. Non-retained edges were reset to 0 to exclude them from the network analyses. We generated and analyzed network weight matrices at four levels: (1) for each subject's full concatenated dataset (up to 4800 TRs); (2) on each step of a sliding window analysis (see Partition Evaluation for more details); (3) for the concatenated time series for the two runs on each day (up to 2400 TRs); and (4) for each run separately (up to 1200 TRs).

### *Community Detection*

Communities (i.e. clusters) were identified using the SP algorithm [@Belkin2003; @chung1997; @Fiedler1975; @Higham2007]. First, each network was represented as an $n$ x $n$ network weight matrix $W$ as described above (where $n$ equals the number of vertices in the search space, 4,801). The matrix was then transformed into its symmetric normalized Laplacian form

$$\begin{aligned}
L = I - D^{-\frac{1}{2}}WD^{-\frac{1}{2}}
\end{aligned}$$

Where $I$ is an identity matrix of size $n$, and $D$ is a diagonal matrix containing the strength of each vertex (i.e. the sum of its edge weights with all other vertices). This resulted in a matrix wherein each entry was the negative normalized value of the connection (from 0 to 1) between any two vertices relative to their combined connectivity strength, and with ones along the diagonal. The transformation ensures that every row sums to zero. We then computed the eigenvalues and eigenvectors of the symmetric normalized Laplacian matrix, and used the eigenvector associated with the second-to-lowest eigenvalue (traditionally called the 'Fiedler vector') to divide the network into two. The Fiedler vector consists of a set of positive and negative values and is binarized by sign to partition the network into two similarly-sized communities [@Fiedler1975]. In this way, SP avoids producing communities that are too small to be physiologically meaningful (for example, small sets of vertices that are spuriously correlated due to measurement noise). Given that this data-driven method does not label the two communities or establish correspondence across participants, we defined each individual's "DN" community as that which contained the DN-specific PCC parcel identified in our meta-analysis. The high density of the graphs ensured that SP did not face the issues associated with its use in sparse networks [@Fortunato2016].

In order to evaluate the validity of the resulting partitionings across community-detection methods, we also estimated network communities using the more traditional approach of modularity maximization [@Garcia2017], based on the algorithm from Clauset et al. [-@Clauset2004]. The method heuristically iterates through many possible combinations of vertices, and selects the partitioning that maximizes the within-community edge weights, relative to a random network containing the same number of edges and communities. Unlike SP, modularity can fractionate a network into more than two communities. Agreement between the partitions provided by the bounded and unbounded community detection methods would suggest the results are not distorted by the restriction of SP to binary partitionings.


### *Partition Evaluation*

We used the Adjusted Rand index (ARI) to evaluate the stability and topographical heterogeneity of the communities within and across individuals [@Hubert1985], which was calculated using the "mcclust" package in R [@Arno2012]. The ARI is a metric that quantifies the similarity between two alternative clusterings of the same data. The base of the ARI is computed by the formula

$$\frac{a + b}{a + b + c + d}$$

where $a$ is the number of pairs of nodes that were grouped together in both partitionings, $b$ is the number that were grouped separately, and $c$ and $d$ denote the number of nodes grouped together (separately) in one partitioning, but separately (together) in the other. Therefore, the ARI estimates the fraction of all possible node pairs that had the same status (connected or not) in both partitionings (with the denominator equal to $n(n - 1)/2$). The resulting ratio is adjusted against a baseline given by the expectation assuming independent partitionings to yield an index that ranges from 0 to 1, where 0 denotes the value expected by chance. This means that even though differences are heavily penalized, positive ARI values compare favorably against chance clustering (and the index can take negative values if the ratio given by the formula above falls below the chance level). In short, the ARI quantifies the chance-corrected agreement between any two partitions while being agnostic to the labeling scheme.

We performed a number of comparisons among partitions. First, we computed the degree of agreement between SP and modularity per subject. SP and Modularity have been previously found to show underfitting and overfitting tendencies, respectively, in their community detection performance in a diverse set of network types [@Ghasemian2018], so alignment between the two algorithms would increase our confidence in the validity of the resulting partitionings. Next, we compared the subject-level SP partitionings across individuals, and calculated the mean pairwise ARI for the group. We then performed the same evaluation for PCC and mPFC separately, and examined whether there were mean differences in overall agreement within these regions by performing a paired permutation analysis (5000 iterations) on all pairwise ARI comparisons across subjects.

To estimate the degree of variability of partitionings per individual we performed a sliding window analysis (20 min windows, 1 min increments, median number of windows per subject = 37, range = 35 - 37), comparing each window's resulting partitioning against the partitioning derived from the subject's whole data set. A 20-min window has previously been found adequate for identifying stable community features in brain networks [@Gordon2017]. We assessed whether the magnitude of the Fiedler vector value for a given vertex (for the full subject-level data set) was associated with the stability of that vertex’s sub-network assignment across time windows. To do this, we fit a mixed effects logistic regression model, in which the dependent variable was the proportion of times each vertex participated in the DN community across windows, and the explanatory variables included a random effect of subject and a fixed effect of the Fiedler vector value for that vertex (derived from their full time series). Based on this relationship, we identified a threshold Fiedler vector value for each subject, such that above-threshold vertices were persistently associated with either DN or non-DN more than 99% of the time.

We then estimated the level of agreement between network partitions estimated using data across individual scan days (with 2 days per participant). If the functional organization estimated by SP is indeed individual-specific, we should see higher agreement within individual (test/re-test across days) than across individuals. We tested this idea by computing the ratio of the mean ARI within and between individuals. Ratios close to one would denote similar within-participant and across-participant alignment, whereas ratios considerably higher than one would suggest that partitions were more similar within-participant than across participants. We then extended this idea by computing the agreement across individual runs (4 per subject). Similar to the day-based analysis, we assessed whether run-level data showed higher agreement within-subject than between subjects. 

### *Seed-based Resting-state Functional Connectivity versus Community Detection*

We evaluated the performance of the SP algorithm in comparison to a simpler partitioning approach based on seed-based functional connectivity. Independently for each day (2 per individual), we estimated each subject's DN partition in mPFC based on its vertex-wise functional correlations (Pearson) with the spatially averaged activity across all vertices in PCC. We compared these seed-based maps with the unthresholded Fiedler vectors produced by SP, with the sign of the Fiedler vector oriented so the DN community was marked by positive values in every subject. We calculated three sets of across-day similarity values for each individual: 1) between the two seed-based maps; 2) between the two SP-based maps; and 3) between seed- and SP-based maps. Because the values in the maps were continuous-valued (and not categorical labels, which would be amenable to ARI), we quantified the similarity between maps in terms of the spatial Spearman correlation across vertices. These spatial correlations were meant to determine the test/re-test reliability of each approach, as well as the overall level of agreement between them. For 7 subjects, the communities produced with one of the days' data sets had split coverage of area 7m, and so our community labeling scheme for the Fiedler vector produced a sign mismatch across days. ARI is robust to such labeling issues, but the inconsistency produced strong negative correlations of the Fiedler vector across days for these individuals. Visual inspection showed that the community layout was well aligned across days, and so we matched the labeling of their partitionings based on the day that sufficiently covered area 7m. 

The two methods were expected to produce somewhat similar results, but the one displaying greater within-subject agreement across days should be preferred (for a discussion on the stability of functional networks see [@Kong2018; @Gratton2018b]). We therefore compared the within-subject spatial correlation coefficients produced by each method through a paired permutation analysis. For each of the 100 individuals, we computed the difference in inter-day correlations between methods, randomized the sign of these values 5000 times, and computed the mean of these differences on each iteration. The empirical difference in means was then evaluated against this permuted distribution.


\bigskip

## Results

### *Meta-analysis*

``` {r Meta-analysis permutation, echo = FALSE, message = FALSE, cache = TRUE}
# Glasser parcels contained in Yeo's 17-net DN and limbic networks on the medial cortical wall
Yeo_labels <- c("L_25_ROI",
              "L_OFC_ROI",
              "L_10v_ROI",
              "R_25_ROI",
              "R_OFC_ROI",
              "R_10v_ROI",
              "L_s32_ROI",
              "L_RSC_ROI",
              "R_RSC_ROI",
              "R_23d_ROI",
              "R_d23ab_ROI",
              "R_31a_ROI",
              "R_31pv_ROI",
              "R_31pd_ROI",
              "R_7m_ROI",
              "R_v23ab_ROI",
              "R_p24_ROI",
              "R_d32_ROI",
              "R_9m_ROI",
              "R_p32_ROI",
              "R_a24_ROI",
              "R_10r_ROI",
              "R_10d_ROI",
              "L_23d_ROI",
              "L_d23ab_RO",
              "L_31a_ROI",
              "L_31pv_ROI",
              "L_31pd_ROI",
              "L_7m_ROI",
              "L_v23ab_ROI",
              "L_p24_ROI",
              "L_d32_ROI",
              "L_9m_ROI",
              "L_p32_ROI",
              "L_a24_ROI",
              "L_10r_ROI",
              "L_10d_ROI",
              "R_s32_ROI",
              "R_9a_ROI",
              "L_PCV_ROI") 

## Permutation analysis
# load parcels reported per study for each corpus
setwd('./Meta_coords/metaresultsPOS')
templist <- dir()
studyList_sv <- lapply(templist, readr::read_csv, col_names = F, col_types = cols())

setwd('../metaresultsDN/')
templist <- dir()
studyList_DN <- lapply(templist, readr::read_csv, col_names = F, col_types = cols())

# raw counts for each area per literature
nRegions_sv <- do.call(rbind, studyList_sv) %>% count #(X1)
nRegions_DN <- do.call(rbind, studyList_DN) %>% count #(X1)
nRegions_all <- left_join(nRegions_sv, nRegions_DN, by = "X1")
 
# optional because it can take a long time to run
if (Permute) {
  
  # reported statistics are computed @ 5k, but it's computationally demanding to do that every time.
  nPerms <- 5000 
  
  # For each permutation, reassign the study labels, maintaining the original number of studies per condition
  nullDist <- mclapply(seq(nPerms), function(permutation) {metaPerm(perm = permutation)})
  nullDist <- do.call(rbind, nullDist)
  
  # Now do the same for the actual data, to see how it compares to the null dist
  tmpDF <- data.frame(Parcel = gsub("_", "", Yeo_labels),
                      SV = sapply(Yeo_labels, function(roi) {length(grep(roi, studyList_sv))}),
                      DN = sapply(Yeo_labels, function(roi) {length(grep(roi, studyList_DN))}),
                      propSV = sapply(Yeo_labels, function(roi) {length(grep(roi, studyList_sv))}) / length(studyList_sv),
                      propDN = sapply(Yeo_labels, function(roi) {length(grep(roi, studyList_DN))}) / length(studyList_DN))
  
  # Perform the prop test for each pair and get the max chi-squared stat + pvalue based on the computed null distribution
  tmpDF$Chi_squared <- apply(tmpDF[, 2:3], 1, function(data) {
    round(prop.test(data, c(length(studyList_sv), length(studyList_DN)))$statistic, digits = 2)
    })
  tmpDF$Pval <- 1 - ecdf(nullDist)(tmpDF$Chi_squared) # probability of finding a chi-squared stat at least as large as the observed under a permuted null distribution
  
  # ROIs that survived the threshold based on Chi-squared value 
  significantROIs <- tmpDF %>% filter(Chi_squared >= quantile(nullDist, 0.95))
  
}

## results!
# 25 bilateral (prportion sv = L: 0.42, R: 0.39; proportion DN = L: 0.18, R: 0.16, Chi = L: 12.91, R: 12.83, both p = 0.005)
# 7m bilateral (prportion sv = L: 0.17, R: 0.15; proportion DN = L: 0.36, R: 0.40, Chi = L: 10.07, R: 18.89, L: p = 0.02, R: p < 0.0001)
# v23ab right (proportion sv = 0.16; proportion DN = 0.36, chi = 11.51, p = 0.01)
# v23ab left (proportion sv = 0.16; proportion DN = 0.32, chi = 8.25, p = 0.06)
# null 95th-q chi <- 8.87 (varies; this was done ith 100 but resembles the 5k one)

```

We performed a coordinate-based meta-analysis to identify cortical surface parcels within mPFC and PCC that were preferentially associated with the DN or valuation literature. Volumetric coordinates from 80 studies with task deactivation contrasts and 198 studies with valuation contrasts were projected onto a cortical surface, and mapped to discrete parcels from a multimodal cortical parcellation [@Glasser2016] to produce a list of brain areas reported per study. The `r length(Yeo_labels)` parcels considered were limited to the medial portion of the default and limbic networks defined by the Yeo et al. [-@Yeo2011] 17-network parcellation. Domain-specificity was tested by first permuting the domain labels across studies (DN or valuation) to create a null distribution for the maximum chi-squared statistic in the search space (see Methods for details). The null distribution was used to identify regions that were reported significantly more often in one literature or the other. 

Figure 1 shows the proportion of times each parcel was reported for each domain, as well as the significant differences between domains. The 95th percentile of the permuted chi-squared distribution was 8.87. Based on this threshold, area 7m in PCC/precuneus was the only parcel to show a preferential association with the DN bilaterally (Left: observed $\chi^2$ = 10.07, *p* = 0.029; Right: observed $\chi^2$ = 18.89, *p* < 0.001). The adjacent area v23 exhibited a similar effect, albeit only unilaterally (Right: observed $\chi^2$ = 11.51, *p* = 0.011; Left: observed $\chi^2$ = 8.25, *p* = 0.067). There appeared to be a bilateral preference toward valuation effects in mPFC area 25 (Left: observed $\chi^2$ = 12.91, *p* = 0.005; Right: observed $\chi^2$ = 12.83, *p* = 0.005); however, closer inspection suggested this effect was driven by subcortical foci centered in adjacent ventral striatum. No other parcels were preferentially implicated in valuation relative to DN. We therefore selected area 7m as an interpretable, bilateral reference point for labeling DN and non-DN communities in the analyses that follow. We note that the area labeled 7m in the parcellation used here [@Glasser2016] is different from (and located inferiorly on the medial surface to) the non-DN area 7m discussed in previous work [@AndrewsHanna2010]. 


### *Individual-level DN and non-DN communities*

``` {r Load Summary Data}
# Load data, create a subject list, get the total n, and the number of vertices
setwd('./Summary/')
temp <- list.files()
subjList <- sapply(temp, substring, first = 1, last = 6)
Summaries <- lapply(temp, read.csv)
nSubj <- length(Summaries)
nVertices <- nrow(Summaries[[1]])

```

Within the mPFC/PCC search space, we estimated the topography of the DN for each individual. Using each individual's full time series (approximately 4800 total TRs from four 14-min scanning runs acquired over two days), we calculated the full vertex-to-vertex correlation matrix for the `r nVertices` surface vertices in the search space. We represented each individual's correlation matrix in the form of a network, with cortical surface vertices as nodes and thresholded/transformed correlation values as edge weights. We then applied the SP community detection algorithm to partition the network into two cohesive functional communities.

Figure 2 shows a representative partitioning of the search space for a single participant (100307; additional examples are presented in Supplemental Figure 1). The SP algorithm subdivides a network according to the positive versus negative values in the Fiedler vector (the eigenvector related to the second-to-lowest eigenvalue of the network's Laplacian matrix, see Methods). Since this is a data-driven approach, there is no a priori labeling for the two communities. We assigned the DN label to the community that contained the DN-specific PCC parcel from the meta-analysis (7m). We oriented each individual's Fiedler vector so positive values corresponded to the DN community, and were assigned a value of 1 in the binarized partitionings (with 0 denoting non-DN). In qualitative terms, the resulting patterns contained substantial DN coverage in posterior PCC (as dictated by our labeling strategy), with non-DN vertices in anterior PCC. The mPFC region tended to include DN vertices in its ventral-anterior and dorsal-anterior areas, with a persistent non-DN pocket between them. This non-DN section extended posteriorly into pregenual cinglate cortex (area a24). 

Before evaluating the degree of generazibility of this topographic pattern across individuals, we examined the validity of the partitionings by comparing them to results from an alternative community detection algorithm, modularity maximization [@Clauset2004]. Modularity seeks to find the set of communities that maximizes within-community connection weights relative to a null model. Since modularity is not constrained to a predetermined number of communities, it was capable of finding more than two in our data set. We quantified the cross-method agreement in terms of the Adjusted Rand Index (ARI; see Methods), which measures the proportion of node pairs in a network that were either clustered together or separately in both partitionings, while being agnostic to labeling schemes and controlling for chance clustering. The ARI normally takes values ranging from 0 to 1, with 0 indicating chance agreement (but can take negative values if the similarity falls below chance).

``` {r Partition comparison: all 2, echo = FALSE, message = FALSE, cache = TRUE}
## Community number evaluation (across and within methods)
# ARI between methods (membership = modularity assignment)
RI_all_within <- comparePartitions(Data = Summaries, Index = "RI", MOI = c("FiedlerBinary", "Membership"), nSubjects = nSubj, subjNames = subjList)

# Number of communities per subject for modularity
nModularity <- sapply(Summaries, function(data) {max(data$Membership)}) 

# Median size of the extra (>2) communities estimated by modularity
modularityCounts <- lapply(Summaries, function(data) {sort(plyr::count(as.character(data$Membership))$freq, decreasing = T)})
modularityCounts_two <- sapply(modularityCounts, function(x) {sum(x[seq(2)], na.rm = T)})
modularityCounts_extra <- sapply(modularityCounts, function(x) {sum(x[3:4], na.rm = T)})

# ARI among individuals
# Note: the upper and lower triangles can totally be combined before plotting, instead of adding one corrplot over another. Might work on that eventually.
RI_all_between <- comparePartitions(Data = Summaries, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)
RI_all_between_lowtri <- RI_all_between[lower.tri(RI_all_between)]

# and now ARI among individuals per region (PCC or mPFC)
posteriorIndx <- Summaries[[1]]$y < 0
tempComm_PCC <- lapply(Summaries, "[", i = posteriorIndx, j =)
tempComm_PFC <- lapply(Summaries, "[", i = !posteriorIndx, j =)
RI_PFC <- comparePartitions(Data = tempComm_PFC, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)
RI_PCC <- comparePartitions(Data = tempComm_PCC, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)

# Let's sttistically compare stuff
testPCC <- RI_PCC[lower.tri(RI_PCC)]
testPFC <- RI_PFC[lower.tri(RI_PFC)]
Overall_PCCvsPFC_permTest <- permute(testPCC, testPFC, statType = mean, paired = T)
Overall_PCCvsPFC_ES <- cohenD(testPCC, testPFC) 
mPFCvs0_wilcox <- wilcox.test(testPFC) # is the mPFC agreement above chance?
mPFCvs0_ES <- cohenD(testPFC)

```

The two clustering methods had high agreement (mean ARI = `r round(mean(RI_all_within$Index), digits = 2)`, SD = `r round(sd(RI_all_within$Index), digits = 2)`). Modularity showed a tendency to produce additional communities (median = `r median(nModularity)`, range = `r range(nModularity)`). However, the additional communities encompassed a small number of vertices (median = `r median(modularityCounts_extra)`, IQR = `r quantile(modularityCounts_extra, 0.25)` - `r quantile(modularityCounts_extra, 0.75)`) compared to the principal two (median = `r median(modularityCounts_two)`, IQR = `r quantile(modularityCounts_two, 0.25)` - `r quantile(modularityCounts_two, 0.75)`), suggesting that a binary partitioning provided a reasonable approximation of the network's true community structure.

Next, we examined the similarity of SP-based partitionings across individuals by computing the ARI between every pair of subjects, and found modestly above-chance agreement overall (mean = `r round(mean(RI_all_between_lowtri), digits = 2)`, SD = `r round(sd(RI_all_between_lowtri), digits = 2)`). Qualitative inspection of the community organization showed good alignment for PCC, whereas the pattern in mPFC was consistent but shifted topographically across subjects. To quantify this heterogeneity in mPFC, we calculated the between-subject ARI for each region separately (Figure 3). The functional topography of PCC was better aligned across individuals (mean = `r round(mean(testPCC), digits = 2)`, SD = `r round(sd(testPCC), digits = 2)`) than mPFC (mean = `r round(mean(testPFC), digits = 2)`, SD = `r round(sd(testPFC), digits = 2)`; paired permutation, *p* `r ifelse(Overall_PCCvsPFC_permTest$Pval == 0, "< 0.001", paste("=", Overall_PCCvsPFC_permTest$Pval))`; Cohen's D = `r round(Overall_PCCvsPFC_ES, digits = 2)`), although the mean ARI in mPFC still exceeded the chance value of zero (Wilcoxon signed rank test, *p* `r ifelse(mPFCvs0_wilcox$p.value == 0, "< 0.001", paste("=", mPFCvs0_wilcox$p.value))`; Cohen's D = `r round(mPFCvs0_ES, digits = 2)`). 

### *Pattern variability over time*

``` {r Variability per subject: Overall, echo = FALSE, message = FALSE, cache = TRUE}
# Load files
# these include the community assignment per window, as well as the agreement per window vs total partitioning
setwd('./Sliding_window/')
temp <- list.files(pattern = '*Comparisons.csv')
SC <- lapply(temp, read.csv2)
temp <- list.files(pattern = '*Values.csv')
SVals <- lapply(temp, read.csv2)

# concatenate all proportion of DN affiliations per node to produce (1) a histogram for fig 4C, and (2) % of node affiliated with either community > 99% over time
allPropDN <- sapply(Summaries, "[[", "slidePropDN")

# proportion of fully stable nodes per individual
prcntStable <- apply(allPropDN, 2, function(subj) {round(mean(subj %in% c(0, 1)), digits = 2)}) * 100

# put all summaries together for model fit
allSummaries <- do.call(rbind, Summaries)
allSummaries$SubjID <- rep(subjList, each = nVertices) 

# Do a mixed effects GLM (binomial, quasi unavailable on glmer) to estimate the relationship between Fiedler vec and propDN
SC_FVvPDN_model <- glmer(slidePropDN ~ FiedlerVec + (1 | SubjID), family = "binomial", data = allSummaries)
SC_FVvPDN_modelSummary <- summary(SC_FVvPDN_model)
allSummaries$FittedVals <- fitted(SC_FVvPDN_model)

# Create a smaller dataframe just to plot the fit
# Otherwise, plotting the thousands fitted can place an unnecessary burden on the document
# (at some point, knitting to pdf wouldn't show the logistic plot because of this)
FiedlerVector <- seq(min(allSummaries$FiedlerVec), max(allSummaries$FiedlerVec), length.out = nVertices)
formula <- SC_FVvPDN_modelSummary$coefficients[1,1] + (SC_FVvPDN_modelSummary$coefficients[2,1] * FiedlerVector)
Fitted_Proportion <- exp(formula) / (1 + exp(formula))
SC_FVvPDN_fits <- data.frame(FiedlerVector, Fitted_Proportion)
rm(FiedlerVector, formula, Fitted_Proportion)

```

We next sought to identify a set of temporally stable core nodes in each community. In order to estimate the stability of partitions over time, we performed a sliding window analysis on each subject's full time series (20 min windows shifting by 1 min). We compared the partitioning derived from each window with the partitioning computed using the entire time series (Figure 4). 

``` {r Variability per subject: PCC vs mPFC, echo = FALSE, message = FALSE, cache = TRUE}
## Check variability for PCC and mPFC separately
tempSW_PCC <- lapply(SVals, "[", i = posteriorIndx, j =)
tempSW_PFC <- lapply(SVals, "[", i = !posteriorIndx, j =)

SC_PCC <- data.frame()
SC_PFC <- data.frame()

# compare the PCC and mPFC partitionings with those produced per window
for (subj in seq(nSubj)) {
  tempPCC <- numeric()
  tempPFC <- numeric()
  nWins <- ncol(tempSW_PCC[[subj]])
  for (Win in seq(nWins)) {
    tempPCC[Win] <- arandi(tempComm_PCC[[subj]]$FiedlerBinary, tempSW_PCC[[subj]][, Win], adjust = T)
    tempPFC[Win] <- arandi(tempComm_PFC[[subj]]$FiedlerBinary, tempSW_PFC[[subj]][, Win], adjust = T)
  }
  dfPCC <- data.frame(SubjID = rep(subjList[subj], nWins),
                      Window = seq(nWins),
                      Index = tempPCC)
  dfPFC <- data.frame(SubjID = rep(subjList[subj], nWins),
                      Window = seq(nWins),
                      Index = tempPFC)
  SC_PCC <- rbind(SC_PCC, dfPCC)
  SC_PFC <- rbind(SC_PFC, dfPFC)
}

# and get descriptives for all individuals
SC_PCC_summary <- aggregate(SC_PCC$Index, by = list(SC_PCC$SubjID), FUN = mean)
SC_PCC_summary$SD <- aggregate(SC_PCC$Index, by = list(SC_PCC$SubjID), FUN = sd)$x
SC_PCC_summary$Region <- rep("PCC", nSubj)
SC_PFC_summary <- aggregate(SC_PFC$Index, by = list(SC_PFC$SubjID), FUN = mean)
SC_PFC_summary$SD <- aggregate(SC_PFC$Index, by = list(SC_PFC$SubjID), FUN = sd)$x
SC_PFC_summary$Region <- rep("mPFC", nSubj)
SC_PCCPFC_summary <- rbind(SC_PFC_summary, SC_PCC_summary)
colnames(SC_PCCPFC_summary) <- list("SubjID", "Index", "SD", "Region")
rm(SC_PCC_summary, SC_PFC_summary)

# Compare mean ARI of sliding windows between regions
SW_PCCvPFC_permuteTest <- permute(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region == "PCC"], SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region == "mPFC"], paired = T)
SW_PCCvPFC_ES <- cohenD(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region == "PCC"], SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region == "mPFC"])

```

The mean ARI along each subject's time series was high for both PCC (mean = `r round(mean(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region=="PCC"]), digits = 2)`; SD = `r round(sd(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region=="PCC"]), digits = 2)`) and mPFC (mean = `r round(mean(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region=="mPFC"]), digits = 2)`; SD = `r round(sd(SC_PCCPFC_summary$Index[SC_PCCPFC_summary$Region=="mPFC"]), digits = 2)`), with significantly higher ARI for PCC (paired permutation, *p* `r ifelse(SW_PCCvPFC_permuteTest$Pval < 0.001, "< 0.001", paste("=", SW_PCCvPFC_permuteTest$Pval))`; Cohen's D = `r round(SW_PCCvPFC_ES, digits = 2)`). A subset of nodes showed exceptionally high stability, in that they were assigned to the same community in every time window. The percentage of stable nodes ranged from 0 to `r max(prcntStable)`% across individuals (median = `r median(prcntStable)`%, IQR = `r quantile(prcntStable, 0.25)`% - `r quantile(prcntStable, 0.75)`%).

We next tested whether the continuous-valued Fiedler vector (before binarization into discrete communities) carried information about the stability of individual nodes. There is precedent in the literature for the idea that the magnitude (and not just the sign) of the Fiedler vector values conveys important information about the role of each node in the network [@Gkantsidis2003; @Tian2018]. Therefore, we tested whether the magnitude of the eigenvector values was associated with the stability of nodes over time. Specifically, we estimated the proportion of DN affiliations per node as a function of Fiedler vector values, using a logistic mixed effects model (Figure 4). The model identified a positive significant relationship between these features ($\beta$ = `r round(SC_FVvPDN_modelSummary$coefficients[2,1], digits = 2)`, SE = `r round(SC_FVvPDN_modelSummary$coefficients[2,2], digits = 2)`, *p* < 0.001), signifying that vertices with higher absolute Fiedler vector values were more persistent in their relationship with their corresponding community over time.

``` {r Threshold values, echo = FALSE, message = FALSE}
# Get a FV threshold for each subject based on mean vertex stability
# Note, the mean resulting threshold is similar to the group's 25th and 75th quantiles
TFV <- safely(threshFV)
tempList <- lapply(Summaries, TFV)

# Store the FV thresholds for all subject 
threshDF <- data_frame(SubjID = substring(subjList, 1, 6),
                       Lower = NA,
                       Upper = NA)
for (i in seq_along(tempList)) {
  if (is.null(tempList[[i]]$result)) {
    # if there wass no clear threshold (i.e. noisy participants), then leave it as 0
    threshDF[i, 2:3] <- c(0, 0)
  } else {
    threshDF[i, 2] <- as.numeric(tempList[[i]]$result[1])
    threshDF[i, 3] <- as.numeric(tempList[[i]]$result[2])
  }
}

# get descriptives
threshDescriptives <- threshDF %>% 
                        filter(Lower < 0, Upper > 0) %>% 
                        summarize(mL = mean(Lower), 
                                  sdL = sd(Lower), 
                                  mU = mean(Upper), 
                                  sdU = sd(Upper)) %>% 
                        round(., digits = 4)

# number of subjects without stable vertices
nUnstable <- threshDF %>% 
                filter(Lower == 0, Upper == 0) %>% 
                nrow

# Apply threshold to Summaries
# IMPORTANT: THIS PROCESS OVERWRITES THE VARIABLES FROM THE FIRST COMPARISON SECTION
# THIS IS DONE FOR STORAGE-SAKE
if (threshMaps) {
  for (i in seq(nSubj)) {
  Summaries[[i]] <- Summaries[[i]] %>%
    mutate(FiedlerVec = ifelse(FiedlerVec > as.numeric(threshDF[i, 2]) & FiedlerVec < as.numeric(threshDF[i, 3]), 0, FiedlerVec)) %>%
    mutate(FiedlerBinary = ifelse(FiedlerVec > 0, 1, ifelse(FiedlerVec < 0, 0, 0.5)))
  }
}

# percent of stable nodes per subject
# this can be different from prcntStable because fully stable vertices can technically have low FV values
# the match between FV and Stability is strong, but not perfect
prcntSurvived <- sapply(Summaries, function(data) {mean(data$FiedlerBinary != 0.5)})

rm(tempList)

```

These analyses suggest that there is potential value in thresholding the Fiedler vector as a means to identify reliable DN and non-DN vertices on an individual subject basis. We therefore thresholded each subject's Fiedler vector to produce these refined maps. For each individual, we estimated the threshold by selecting the smallest absolute Fiedler vector value that yielded an average stability across suprathreshold nodes of 99%, for positive (mean = `r threshDescriptives[3]`, SD = `r threshDescriptives[4]`) and negative (mean = `r threshDescriptives[1]`, SD = `r threshDescriptives[2]`) values separately. Individuals without such stable nodes (n = `r nUnstable`) were not thresholded, and were included in the subsequent analyses in unthresholded form. The median proportion of retained vertices per individual was `r round(median(prcntSurvived), digits = 2)` (IQR = `r round(quantile(prcntSurvived, 0.25), digits = 2)` - `r round(quantile(prcntSurvived, 0.75), digits = 2)`). Sub-threshold vertices were set to zero in Fiedler vector maps and 0.5 in the binarized maps (so that they would not bias the calculation of averages). Figure 5A shows the thresholded partitioning for the same individual shown in Figure 2. The maps used in all subsequent analyses were thresholded by this individualized criterion. 

``` {r Partition comparison: all thresholded, echo = FALSE, message = FALSE, cache = TRUE}
## Compare partitionings
# Across subjects
# Note: the upper and lower triangles can totally be combined before plotting, instead of adding one corrplot over another. Might work on that eventually.
RI_all_between <- comparePartitions(Data = Summaries, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)
RI_all_between_lowtri <- RI_all_between[lower.tri(RI_all_between)]

# ARI among subjects for each region separately
posteriorIndx <- Summaries[[1]]$y < 0
tempComm_PCC <- lapply(Summaries, "[", i = posteriorIndx, j =)
tempComm_PFC <- lapply(Summaries, "[", i = !posteriorIndx, j =)
RI_PFC <- comparePartitions(Data = tempComm_PFC, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)
RI_PCC <- comparePartitions(Data = tempComm_PCC, Index = "RI", nSubjects = length(Summaries), subjNames = subjList)

# Let's statistically compare stuff
testPCC <- RI_PCC[lower.tri(RI_PCC)]
testPFC <- RI_PFC[lower.tri(RI_PFC)]
Overall_PCCvsPFC_permTest <- permute(testPCC, testPFC, statType = mean, paired = T)
Overall_PCCvsPFC_ES <- cohenD(testPCC, testPFC) 

# To get the rate of stability per vertex across subjects (used for plotting)
FB <- do.call(cbind, lapply(Summaries, "[[", "FiedlerBinary"))
FV <- do.call(cbind, lapply(Summaries, "[[", "FiedlerVec"))
FBS <- rowMeans(FB)
FBS[FBS < 0.5] <- 1 - FBS[FBS < 0.5]

```

With these thresholded partitions, we recomputed the overall similarity across participants. Compared to before, there was lower topographic agreement across individuals (mean ARI = `r round(mean(RI_all_between_lowtri), digits = 2)`, SD = `r round(sd(RI_all_between_lowtri), digits = 2)`). The same was true for both PCC (mean = `r round(mean(testPCC), digits = 2)`, SD = `r round(sd(testPCC), digits = 2)`) and mPFC (mean = `r round(mean(testPFC), digits = 2)`, SD = `r round(sd(testPFC), digits = 2)`) separately, although the significance of the differences between areas was preserved (paired permutation, *p* `r ifelse(Overall_PCCvsPFC_permTest$Pval == 0, "< 0.001", paste("=", Overall_PCCvsPFC_permTest$Pval))`; Cohen's D = `r round(Overall_PCCvsPFC_ES, digits = 2)`). Figure 5B shows the average of the thresholded partitions across all participants, denoting the proportion of times a vertex was affiliated with the DN community. This summary illustrates the common organizational layout of both communities, but also highlights the considerable variability across individuals.

``` {r tSNR evaluation, echo = FALSE, message = FALSE, cache = TRUE}
## next get the mean tSNR of PCC and mPFC before/after thresholding
# the first piece of code gets each subject's mean tSNR per region, and reduces to a single matrix
# the second one is similar, but filtering out vertices that didn't meet the threshold
# the third one applies summary stats to each list to create a summary table
snr_means <- list()

snr_means$pre_thresh <- lapply(Summaries, function(data) {
  data %>% 
    mutate(region = ifelse(y > 0, "mPFC", "PCC")) %>%
    group_by(region) %>% 
    dplyr::summarise(mean_tsnr = mean(tSNR)) %>%
    ungroup()
}) %>% reduce(left_join, by = "region")

snr_means$post_thresh <- lapply(Summaries, function(data) {
  data %>% 
    filter(FiedlerBinary != 0.5) %>%
    mutate(region = ifelse(y > 0, "mPFC", "PCC")) %>%
    group_by(region) %>% 
    dplyr::summarise(mean_tsnr = mean(tSNR)) %>%
    ungroup()
}) %>% reduce(left_join, by = "region")

# and compute summary stats on each 
snr_means$overall <- sapply(snr_means, function(x) {
  c(rowMeans(x[, -1]), apply(x[, -1], 1, sd))
})
rownames(snr_means$overall) <- c("mPFC_mean", "PCC_mean", "mPFC_SD", "PCC_SD")

# permutation pre vs post
tsnrPermute_mPFC <- permute(as.numeric(snr_means$pre_thresh[1, -1]), as.numeric(snr_means$post_thresh[1, -1]), paired = T)
tsnrPermute_PCC <- permute(as.numeric(snr_means$pre_thresh[2, -1]), as.numeric(snr_means$post_thresh[2, -1]), paired = T)
tsnrPermute_Post <- permute(as.numeric(snr_means$post_thresh[1, -1]), as.numeric(snr_means$post_thresh[2, -1]))

# effect size pre vs post
tsnrCohen_mPFC <- CohenD(as.numeric(snr_means$post_thresh[1, -1]), as.numeric(snr_means$pre_thresh[1, -1]))
tsnrCohen_PCC <- CohenD(as.numeric(snr_means$post_thresh[2, -1]), as.numeric(snr_means$pre_thresh[2, -1]))
tsnrCohen_Post <- CohenD(as.numeric(snr_means$post_thresh[1, -1]), as.numeric(snr_means$post_thresh[2, -1]))
```

To test the possibility that the higher inter-subject variability in mPFC was driven merely by lower signal quality in the retained vertices, we quantified the temporal signal to noise ratio (tSNR) for each region, both before and after thresholding. We calculated tSNR using time series that were not demeaned, but were otherwise equivalent to the data originally used. In terms of tSNR variability across vertices within each region, mPFC had overall greater spatial standard deviation both before and after thresholding (mPFC: pre-threshold mean spatial SD = 33.96, post-threshold mean spatial SD = 30.15; PCC: pre-threshold mean spatial SD = 15.28, post-threshold mean spatial SD = 14.59). However, tSNR after thresholding was significantly higher for mPFC than PCC (mPFC: mean = `r round(snr_means$overall[1, 2], digits = 2)`, SD = `r round(snr_means$overall[3, 2], digits = 2)`; PCC: mean = `r round(snr_means$overall[2, 2], digits = 2)`, SD = `r round(snr_means$overall[4, 2], digits = 2)`; permutation p-value `r ifelse(tsnrPermute_Post$Pval < 0.001, "< 0.001", paste("=", tsnrPermute_Post$Pval))`, Cohen's D = `r round(tsnrCohen_Post[1], digits = 2)`). This reflected a significant increase in mean tSNR in mPFC as a result of the thresholding step (pre-threshold mean = `r round(snr_means$overall[1, 1], digits = 2)`, SD = `r round(snr_means$overall[3, 1], digits = 2)`; paired permutation p-value `r ifelse(tsnrPermute_mPFC$Pval < 0.001, "< 0.001", paste("=", tsnrPermute_mPFC$Pval))`, Cohen's D = `r round(tsnrCohen_mPFC[1], digits = 2)`), whereas the mean signal quality in PCC was unchanged (pre-threshold mean = `r round(snr_means$overall[2, 1], digits = 2)`, SD = `r round(snr_means$overall[4, 1], digits = 2)`; paired permutation p-value = `r tsnrPermute_PCC$Pval`, Cohen's D = `r round(tsnrCohen_PCC[1], digits = 2)`). In short, mPFC had higher overall tSNR, albeit with greater variability across nodes. Applying the thresholding step allowed us to focus the analysis on vertices with high signal quality. 


### *Test/re-test reliability across days*

The relatively high inter-individual variability seen in the aggregate map could reflect at least three factors: (1) measurement noise, (2) dynamic variation in mPFC network organization, and (3) stable patterns of functional organization that differ across individuals. To arbritrate among these possibilities, we examined the test/re-test reliability of mPFC/PCC community structure across separate days of testing. Insofar as the observed variability reflects individual-specific brain organization, across-day ARI values should be consistently higher within-individual than between individuals (an example comparison for two individuals is provided in Supplemental Figure 2). Figure 6 shows pairwise comparisons among ten example subjects for PCC and mPFC separately (left).

``` {r Partition comparison: halves, echo = FALSE, message = FALSE, cache = TRUE}
# Load data
setwd('./Summary_halves/')
temp <- list.files(pattern = "*_finalSummary.csv")
subjList_halves <- sapply(temp, substring, first=1, last=9)
Summaries_halves <- lapply(temp, read.csv)

# Before thresholding, capture within/between daily comparisons for FV vs correlation analysis (only for daily)
# Some subjects didn't have the correct labeling scheme in one of their days (see corr vs FV below), so we manually reverted it after visual inspection
revertSubjs <- c("144226_H2", "165840_H1", "192843_H1", "303624_H1", "687163_H1", "108525_H2", "156637_H1")
for (subj in revertSubjs) {
  indx <- grep(subj, subjList_halves)
  Summaries_halves[[indx]] <- transform(Summaries_halves[[indx]], FiedlerVec = FiedlerVec * -1)
}
Summaries_halves_unthresh <- Summaries_halves

# Some participants have strongly uncorrelated maps because 7m isn't fully covered on one of the days
# ARI doesn't mind this, so the results are fine
# But the Corr vs FV analysis below is badly affected
unCorrParticipants <- data.frame(SubjID = subjList,
                                 Corrs = sapply(seq(1, nSubj * 2, by = 2), function(x) {cor(Summaries_halves_unthresh[[x]]$FiedlerVec, Summaries_halves_unthresh[[x+1]]$FiedlerVec)})) %>%
  filter(Corrs < 0)

# Load the correlation-based maps from each day for analysis in a subsequent section
temp <- list.files(pattern = "*_corHalves.csv")
Correlation_halves <- lapply(temp, read.csv, header = F)

# Apply threshold to Summaries
if (threshMaps) {
  # create a vector of repeated indices, so each threshold is applied to each subject twice
  threshindex <- rep(seq(nSubj), each = 2)
  count <- 1
  for (i in threshindex) {
    Summaries_halves[[count]] <- Summaries_halves[[count]] %>%
            mutate(FiedlerVec = ifelse(FiedlerVec > as.numeric(threshDF[i, 2]) & FiedlerVec < as.numeric(threshDF[i, 3]), 0, FiedlerVec)) %>%
            mutate(FiedlerBinary = ifelse(FiedlerVec > 0, 1, ifelse(FiedlerVec < 0, 0, 0.5)))
    count <- count + 1
  }
}

```

``` {r Partition comparison: halves ratios, echo = FALSE, message = FALSE, cache = TRUE}
## Now compare all possible pairs of subjects (for actual reporting)
# Compare all halves with RI
RI_all_between_halves <- comparePartitions(Data = Summaries_halves, Index = "RI", nSubjects = length(Summaries_halves), subjNames = subjList_halves)

# Compare PCC and PFC among all subjects
tempComm_PCC_halves <- lapply(Summaries_halves, "[", i = posteriorIndx, j =)
tempComm_PFC_halves <- lapply(Summaries_halves, "[", i = !posteriorIndx, j =)
RI_PFC_halves <- comparePartitions(Data = tempComm_PFC_halves, Index = "RI", nSubjects = length(Summaries_halves), subjNames = subjList_halves)
RI_PCC_halves <- comparePartitions(Data = tempComm_PCC_halves, Index = "RI", nSubjects = length(Summaries_halves), subjNames = subjList_halves)

## Let's compare stuff (not accounting for complex interdependencies in the observations)
## Overall differences in mean RI between PCC and mPFC
lowPCC_halves <- RI_PCC_halves[lower.tri(RI_PCC_halves)]
lowPFC_halves <- RI_PFC_halves[lower.tri(RI_PFC_halves)]
Halves_PCCvPFC_perm <- permute(lowPCC_halves, lowPFC_halves, statType = mean, paired = T)
Halves_PCCvPFC_ES <- cohenD(lowPCC_halves, lowPFC_halves) # caveat: maybe not ideal for bounded values, like RI. BUT VI yields similar results.


## Differences in RI values for sessions within vs between subjects (all subjects pooled together)
# create a selection matrix containing all within-subject session comparisons
template <- diagBlocks(ncol(RI_all_between_halves), 2) 
lowTemplate <- template[lower.tri(template)]

# Overall
# First list element is the within subject values, second is the between subject values
lowRIHalves <- RI_all_between_halves[lower.tri(RI_all_between_halves)]
Halves_overallComparison <- list(lowRIHalves[lowTemplate],
                                lowRIHalves[!lowTemplate])
Halves_overallComparison[[3]] <- permute(Halves_overallComparison[[1]], Halves_overallComparison[[2]])
Halves_overallComparison[[4]] <- cohenD(Halves_overallComparison[[1]], Halves_overallComparison[[2]])

# PCC 
Halves_PCCComparison <- list(lowPCC_halves[lowTemplate],
                           lowPCC_halves[!lowTemplate])
Halves_PCCComparison[[3]] <- permute(Halves_PCCComparison[[1]], Halves_PCCComparison[[2]])
Halves_PCCComparison[[4]] <- cohenD(Halves_PCCComparison[[1]], Halves_PCCComparison[[2]])

# mPFC
Halves_PFCComparison <- list(lowPFC_halves[lowTemplate],
                           lowPFC_halves[!lowTemplate])
Halves_PFCComparison[[3]] <- permute(Halves_PFCComparison[[1]], Halves_PFCComparison[[2]])
Halves_PFCComparison[[4]] <- cohenD(Halves_PFCComparison[[1]], Halves_PFCComparison[[2]])


## Ratio of mean within subject sessions over between subject ones (per-subject)
# Overall
# Split the within-subject session RI values per subject
withinSubjVals <- RI_all_between_halves[lower.tri(RI_all_between_halves)][lowTemplate]

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_all_between_halves), by = 2), function(x) RI_all_between_halves[-(x:(x+1)), x:(x+1)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Halves_RIRatios_overall <- sapply(seq(nSubj), function(i) {withinSubjVals[[i]] / mean(betweenSubjVals[[i]])})


# PCC
# Split the within-subject session RI values per subject
withinSubjVals <- RI_PCC_halves[lower.tri(RI_PCC_halves)][lowTemplate]

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_PCC_halves), by = 2), function(x) RI_PCC_halves[-(x:(x+1)), x:(x+1)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Halves_RIRatios_PCC <- sapply(seq(nSubj), function(i) {withinSubjVals[[i]] / mean(betweenSubjVals[[i]])})

# PFC
# Split the within-subject session RI values per subject
withinSubjVals <- RI_PFC_halves[lower.tri(RI_PFC_halves)][lowTemplate]

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_PFC_halves), by = 2), function(x) RI_PFC_halves[-(x:(x+1)), x:(x+1)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Halves_RIRatios_PFC <- sapply(seq(nSubj), function(i) {withinSubjVals[[i]] / mean(betweenSubjVals[[i]])})


# Summarize for plotting
Halves_RIRatios_summary <- data.frame(Region = c(rep("PCC", nSubj), rep("mPFC", nSubj)),
                                      RI = c(Halves_RIRatios_PCC, Halves_RIRatios_PFC))


## Stats
# one-sample signed rank per region
Halves_PCC_ratioTest <- wilcox.test(Halves_RIRatios_PCC, mu = 1, alternative = "greater")
Halves_PFC_ratioTest <- wilcox.test(Halves_RIRatios_PFC, mu = 1, alternative = "greater")

# between regions
Halves_mPFCvPCC_permTest <- permute(Halves_RIRatios_PFC, Halves_RIRatios_PCC, paired = T, statType = median)
Halves_mPFCvPCC_ES <- cohenD(Halves_RIRatios_PFC, Halves_RIRatios_PCC)


# Select a submatrix with the best-performing subjects to show on the matrix figures
# These will be also displayed on the session matrix
# This way I don't have to recompute stuff
tmp <- data_frame(SubjID = subjList,
                  DailyARI = Halves_PFCComparison[[1]])
best <- tmp %>% top_n(10, wt = DailyARI) 
bestindx <- substr(subjList_halves, 1, 6) %in% best$SubjID

RI_all_between_halves_plot <- RI_all_between_halves[bestindx, bestindx]
RI_PFC_halves_plot <- RI_PFC_halves[bestindx, bestindx]
RI_PCC_halves_plot <- RI_PCC_halves[bestindx, bestindx]

# Get the same subsection of participants for the correlation plots
Correlation_halves_plot <- Correlation_halves[bestindx] 

# Save unthresholded subjects for comparing and plotting against correlation maps
unthreshComm_PFC_halves_plot <- lapply(Summaries_halves_unthresh[bestindx], "[", i = !posteriorIndx, j =)
unthreshComm_PFC_halves <- lapply(Summaries_halves_unthresh, "[", i = !posteriorIndx, j =)
```

Once again we found low alignment across individuals for PCC (mean = `r round(mean(Halves_PCCComparison[[2]]), digits = 2)`, SD = `r round(sd(Halves_PCCComparison[[2]]), digits = 2)`) and mPFC (mean = `r round(mean(Halves_PFCComparison[[2]]), digits = 2)`, SD = `r round(sd(Halves_PFCComparison[[2]]), digits = 2)`), but both areas showed comparatively high levels of within-individual agreement (PCC: mean = `r round(mean(Halves_PCCComparison[[1]]), digits = 2)`, SD = `r round(sd(Halves_PCCComparison[[1]]), digits = 2)`; mPFC: mean = `r round(mean(Halves_PFCComparison[[1]]), digits = 2)`, SD = `r round(sd(Halves_PFCComparison[[1]]), digits = 2)`). We calculated an index of relative specificity by computing the ratio of each individual’s across-day (within-participant) ARI to the mean of all between-participant ARI values involving that individual. The index is expected to take on a value near 1 if partitionings are well aligned across individuals and/or are subject to a common level of measurement noise. It is expected to exceed 1 insofar as functional network organization is reliable and individual-specific. This index is intended to factor out the potential contributions of measurement noise or dynamic instability, which would introduce variability both across individuals and across days.

Figure 6 shows ARI ratios for PCC and mPFC. A signed-rank test showed evidence for specificity (i.e. ratios > 1) in both mPFC (median = `r round(median(Halves_RIRatios_PFC), digits = 2)`, IQR = `r round(quantile(Halves_RIRatios_PFC, 0.25), digits = 2)` - `r round(quantile(Halves_RIRatios_PFC, 0.75), digits = 2)`, V = `r Halves_PFC_ratioTest$statistic`, *p* `r ifelse(Halves_PFC_ratioTest$p.value < 0.001, "< 0.001", paste("=", Halves_PFC_ratioTest$p.value))`) and PCC (median = `r round(median(Halves_RIRatios_PCC), digits = 2)`, IQR = `r round(quantile(Halves_RIRatios_PCC, 0.25), digits = 2)` - `r round(quantile(Halves_RIRatios_PCC, 0.75), digits = 2)`, V = `r Halves_PCC_ratioTest$statistic`, *p* `r ifelse(Halves_PCC_ratioTest$p.value < 0.001, "< 0.001", paste("=", Halves_PCC_ratioTest$p.value))`). Moreover, the ratios for mPFC were significantly greater than those for PCC when compared with a paired permutation test (*p* `r ifelse(Halves_mPFCvPCC_permTest$Pval < 0.001, "< 0.001", paste("=", Halves_mPFCvPCC_permTest$Pval))`; Cohen's D = `r round(Halves_mPFCvPCC_ES, digits = 2)`). These test/retest results suggest that the topographic variability seen in mPFC arises at least in part from stable and subject-specific organizational patterns. We stress that our similarity metric, the ARI, measured the similarity of partitionings in a label-agnostic manner. The greater inter-individual consistency in PCC was therefore not merely an artifact of having used a PCC subregion as the basis for label assignment. 

### *Test/re-test reliability across runs*

We extended the analysis of per-day data by examining whether the organization of the DN could be extracted using per-run data only. The duration of each run (approximately 14 min) falls below a previously suggested stability threshold for fMRI-based modularity estimations [@Gordon2017]. Nonetheless, high ARI ratios would indicate that the SP algorithm can reliably estimate individual-specific patterns of DN organization from a single run of data.

``` {r Partition comparison: session similarity matrices, echo = FALSE, message = FALSE, cache = TRUE}
# Load data
setwd('./Summary_sess/')
temp <- list.files()
subjList_sess <- sapply(temp, substring, first = 1, last = 9)
Summaries_sess <- lapply(temp, read.csv)

# Apply threshold to Summaries
if (threshMaps) {
  # create a vector of repeated indices, so each threshold is applied to each subject twice
  threshindex <- rep(seq(nSubj), each = 4)
  count <- 1
  for (i in threshindex) {
    Summaries_sess[[count]] <- Summaries_sess[[count]] %>%
            mutate(FiedlerVec = ifelse(FiedlerVec > as.numeric(threshDF[i,2]) & FiedlerVec < as.numeric(threshDF[i,3]), 0, FiedlerVec)) %>%
            mutate(FiedlerBinary = ifelse(FiedlerVec > 0, 1, ifelse(FiedlerVec < 0, 0, 0.5)))
    count <- count + 1
  }
}

```

``` {r Partition comparison: session compare all, echo = FALSE, message = FALSE, cache = TRUE}
# Now run comparisons among all subjects (for actual reporting)
RI_all_between_sess <- comparePartitions(Data = Summaries_sess, Index = "RI", nSubjects = length(Summaries_sess), subjNames = subjList_sess)
tempComm_PCC_sess <- lapply(Summaries_sess, "[", i = posteriorIndx, j =)
tempComm_PFC_sess <- lapply(Summaries_sess, "[", i = !posteriorIndx, j =)
RI_PFC_sess <- comparePartitions(Data = tempComm_PFC_sess, Index = "RI", nSubjects = length(Summaries_sess), subjNames = subjList_sess)
RI_PCC_sess <- comparePartitions(Data = tempComm_PCC_sess, Index = "RI", nSubjects = length(Summaries_sess), subjNames = subjList_sess)

## Let's compare stuff (not accounting for complex interdependencies in the observations)
## Overall differences in mean RI between PCC and mPFC
lowPCC_sess <- RI_PCC_sess[lower.tri(RI_PCC_sess)]
lowPFC_sess <- RI_PFC_sess[lower.tri(RI_PFC_sess)]
Sess_PCCvPFC_perm <- permute(lowPCC_sess, lowPFC_sess, statType = mean, paired = T)
Sess_PCCvPFC_ES <- cohenD(lowPCC_sess, lowPFC_sess) # caveat: maybe not ideal for bounded values, like RI. BUT VI yields similar results.


## Differences in RI values for sessions within vs between subjects (all subjects pooled together)

# create a selection matrix containing all within-subject session comparisons
template <- diagBlocks(ncol(RI_all_between_sess), 4) 
lowTemplate <- template[lower.tri(template)]

# Overall
# First list element is the within subject values, second is the between subject values
lowRISess <- RI_all_between_sess[lower.tri(RI_all_between_sess)]
Sess_overallComparison <- list(lowRISess[lowTemplate],
                               lowRISess[!lowTemplate])
Sess_overallComparison[[3]] <- permute(Sess_overallComparison[[1]], Sess_overallComparison[[2]])
Sess_overallComparison[[4]] <- cohenD(Sess_overallComparison[[1]], Sess_overallComparison[[2]])

# PCC 
Sess_PCCComparison <- list(lowPCC_sess[lowTemplate],
                           lowPCC_sess[!lowTemplate])
Sess_PCCComparison[[3]] <- permute(Sess_PCCComparison[[1]], Sess_PCCComparison[[2]])
Sess_PCCComparison[[4]] <- cohenD(Sess_PCCComparison[[1]], Sess_PCCComparison[[2]])

# mPFC
Sess_PFCComparison <- list(lowPFC_sess[lowTemplate],
                           lowPFC_sess[!lowTemplate])
Sess_PFCComparison[[3]] <- permute(Sess_PFCComparison[[1]], Sess_PFCComparison[[2]])
Sess_PFCComparison[[4]] <- cohenD(Sess_PFCComparison[[1]], Sess_PFCComparison[[2]])

# Select the best performing for plotting, from daily performance
bestindx <- substr(subjList_sess,1,6) %in% best$SubjID
RI_all_between_sess_plot <- RI_all_between_sess[bestindx, bestindx]
RI_PFC_sess_plot <- RI_PFC_sess[bestindx, bestindx]
RI_PCC_sess_plot <- RI_PCC_sess[bestindx, bestindx]
```

Run-specific SP results still captured unique organizational patterns to some degree, even though the overall levels of agreement decreased (PCC between subjects: mean = `r round(mean(Sess_PCCComparison[[2]]), digits = 2)`, SD = `r round(sd(Sess_PCCComparison[[2]]), digits = 2)`; mPFC between subjects: mean = `r round(mean(Sess_PFCComparison[[2]]), digits = 2)`, SD = `r round(sd(Sess_PFCComparison[[2]]), digits = 2)`; PCC within subjects: mean = `r round(mean(Sess_PCCComparison[[1]]), digits = 2)`, SD = `r round(sd(Sess_PCCComparison[[1]]), digits = 2)`; mPFC within subjects: mean = `r round(mean(Sess_PFCComparison[[1]]), digits = 2)`, SD = `r round(sd(Sess_PFCComparison[[1]]), digits = 2)`). We again computed each subject's ARI ratio in order to quantify the specificity of the partitions, this time using the mean of 6 across-run (within-participant) ARI values in the numerator of the ratio (Figure 6, right). 

``` {r Partition comparison: session ratios, echo = FALSE, message = FALSE, cache = TRUE}
# Ratio of mean within subject sessions over between subject ones (per-subject)
# Overall
# Split the within-subject session RI values per subject
temp <- ceiling(seq_along(Sess_overallComparison[[1]])/6)
withinSubjVals <- split(Sess_overallComparison[[1]], temp) 

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_all_between_sess), by = 4), function(x) RI_all_between_sess[-(x:(x+3)), x:(x+3)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Sess_RIRatios_overall <- sapply(seq(nSubj), function(i) {mean(withinSubjVals[[i]]) / mean(betweenSubjVals[[i]])})

# PCC
temp <- ceiling(seq_along(Sess_PCCComparison[[1]])/6)
withinSubjVals <- split(Sess_PCCComparison[[1]], temp) 

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_PCC_sess), by = 4), function(x) RI_PCC_sess[-(x:(x+3)), x:(x+3)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Sess_RIRatios_PCC <- sapply(seq(nSubj), function(i) {mean(withinSubjVals[[i]]) / mean(betweenSubjVals[[i]])})

# PFC
temp <- ceiling(seq_along(Sess_PFCComparison[[1]])/6)
withinSubjVals <- split(Sess_PFCComparison[[1]], temp) 

# Now grab the columns from the similarity matrix for a subject
betweenSubjVals <- lapply(seq(1, ncol(RI_PFC_sess), by = 4), function(x) RI_PFC_sess[-(x:(x+3)), x:(x+3)])

# And get a vector of the meanWithin / meanBetween ratio per subject
Sess_RIRatios_PFC <- sapply(seq(nSubj), function(i) {mean(withinSubjVals[[i]]) / mean(betweenSubjVals[[i]])})

# Summarize for plotting
Sess_RIRatios_summary <- data.frame(Region = c(rep("PCC", nSubj), rep("mPFC", nSubj)),
                                    RI = c(Sess_RIRatios_PCC, Sess_RIRatios_PFC))

## Stats
# one-sample signed rank per region
Sess_PCC_ratioTest <- wilcox.test(Sess_RIRatios_PCC, mu = 1, alternative = "greater")
Sess_PFC_ratioTest <- wilcox.test(Sess_RIRatios_PFC, mu = 1, alternative = "greater")

# between
Sess_mPFCvPCC_permTest <- permute(Sess_RIRatios_PFC, Sess_RIRatios_PCC, paired = T, statType = median)
Sess_mPFCvPCC_ES <- cohenD(Sess_RIRatios_PFC, Sess_RIRatios_PCC)
```

As before, a signed rank test showed that both regions had ARI ratios significantly greater than 1 (mPFC: median = `r round(median(Sess_RIRatios_PFC), digits = 2)`, IQR = `r round(quantile(Sess_RIRatios_PFC, 0.25), digits = 2)` - `r round(quantile(Sess_RIRatios_PFC, 0.75), digits = 2)`, V = `r Sess_PFC_ratioTest$statistic`, *p* `r ifelse(Sess_PFC_ratioTest$p.value < 0.001, "< 0.001", paste("=", Sess_PFC_ratioTest$p.value))`; PCC: median = `r round(median(Sess_RIRatios_PCC), digits = 2)`, IQR = `r round(quantile(Sess_RIRatios_PCC, 0.25), digits = 2)` - `r round(quantile(Sess_RIRatios_PCC, 0.75), digits = 2)`, V = `r Sess_PCC_ratioTest$statistic`, *p* `r ifelse(Sess_PFC_ratioTest$p.value < 0.001, "< 0.001", paste("=", Sess_PCC_ratioTest$p.value))`), and ratios for mPFC were higher than those of PCC (permutation *p* = `r ifelse(Sess_mPFCvPCC_permTest$Pval < 0.001, "< 0.001", paste("=", Sess_mPFCvPCC_permTest$Pval))`; Cohen's D = `r round(Sess_mPFCvPCC_ES, digits = 2)`). This result further confirms that the intrinsic functional organization of mPFC is uniquely arranged per individual, and provides evidence that information about such patterns can be extracted from relatively small amounts of data.

### *Correlation vs community detection in mPFC*

``` {r Correlation vs community detection: compute, fig.align="center", echo=FALSE, message = FALSE, cache = TRUE}
## Between halves analysis for correlation and communities (mPFC only)
# Spearman to avoid issues with the differences in value ranges
unthreshComm_PFC_halves_plot <- lapply(seq_along(unthreshComm_PFC_halves_plot), function(x) cbind(unthreshComm_PFC_halves_plot[[x]], Correlation_halves_plot[[x]]))
D1 <- unthreshComm_PFC_halves_plot
D2 <- lapply(unthreshComm_PFC_halves_plot, function(data) transform(data, V1 = FiedlerVec)) # the comparison function can only take 1 column name for this stuff
Data <- c(D1, D2)
subjList_halves_plot <- rep(best$SubjID, each = 2)
allHalfCombs <- comparePartitions(Data = Data, MOI = "V1", nSubjects = 40, Index = "Cor", subjNames = c(subjList_halves_plot, subjList_halves_plot))

```

``` {r Correlation vs community detection: comparison, fig.align="center", echo=FALSE, message = FALSE, cache = TRUE}
# Compare correlation with community approach on mPFC
# correlations among methods
tempComm <- sapply(seq(1, length(unthreshComm_PFC_halves), by = 2), function(x) cor(unthreshComm_PFC_halves[[x]]$FiedlerVec, unthreshComm_PFC_halves[[x+1]]$FiedlerVec))
tempCor <- sapply(seq(1, length(unthreshComm_PFC_halves), by = 2), function(x) cor(Correlation_halves[[x]]$V1, Correlation_halves[[x+1]]$V1))
tempBoth <- sapply(seq(1, length(unthreshComm_PFC_halves), by = 2), function(x) cor(unthreshComm_PFC_halves[[x]]$FiedlerVec, Correlation_halves[[x+1]]$V1))

# put together in a data frame
prepostComp <- data.frame(Community = tempComm, Correlation = tempCor, Between = tempBoth)
prepostComp <- melt(prepostComp)
colnames(prepostComp) <- c("Approach", "Correlation")

# paired permutations and effect sizes for within-subj perm vs corr
prepostComp_permTest <- permute(tempComm, tempCor, paired = T)
prepostComp_ES <- cohenD(tempComm, tempCor)
```

We next explored the possible advantage of community detection relative to a more conventional seed-based functional connectivity analysis for estimating the individual-specific functional topography of mPFC. We examined whether maps generated with SP were more similar per participant across days than those computed from seed-based correlations. We generated a seed time-series by averaging all vertices in the PCC region of our search space, and calculated its correlation with the activity of each vertex in mPFC. We compared the map of correlation values in mPFC to the map of unthresholded Fiedler vector values using Spearman correlations across vertices. Pairwise spatial correlations were calculated among maps computed for each day and method from all individuals. Figure 7A shows that these pairwise comparisons resemble those from the across-day comparisons above, and suggests good alignment between methods, but particularly high agreement within subject and method.

Figure 7B shows the test/re-test reliability across days for patterns derived using community detection, seed-based correlation, and across methods (e.g. Day 1 community detection versus Day 2 seed-based correlation). While both approaches were reliable, community detection displayed a significantly higher mean correlation coefficient across days than seed-based correlation (Community: mean = `r round(mean(tempComm), digits = 2)`, SD = `r round(sd(tempComm), digits = 2)`; Seed-based: mean = `r round(mean(tempCor), digits = 2)`, SD = `r round(sd(tempCor), digits = 2)`; paired permutation *p* `r ifelse(prepostComp_permTest$Pval < 0.001, "< 0.001", paste("=", round(prepostComp_permTest$Pval, digits = 3)))`; Cohen's D = `r round(prepostComp_ES, digits = 2)`). Agreement across methods was fair (mean = `r round(mean(tempBoth), digits = 2)`, SD = `r round(sd(tempBoth), digits = 2)`), signifying that the two approaches identified similar topographic features but also had systematic differences. These findings suggest that graph-theoretic community detection algorithms are advantageous for detecting stable functional topologies, in addition to their other advantages of being data-driven, unbiased and observer agnostic.

### *Alignment of mPFC community structure with a proposed DN sub-network organization*

The thresholded partitions we identified had conceptual and topographic similarities to DN sub-networks A and B proposed by Braga and Buckner [-@Braga2017]. We explored the relationship between the two sets of sub-regions by reproducing their seed-based connectivity approach in two of our subjects. In their original work, Braga and Buckner [-@Braga2017] manually selected individual vertices in areas including the dorsolateral prefrontal cortex (DLPFC), temporo-parietal junction (TPJ), and parahippocampal cortex (PHC) that produced two spatially anticorrelated networks [@Braga2017; @Braga2019]. We hypothesized that if the SP communities corresponded to one or both of the previously proposed sub-networks, our partitionings should match networks A and B generated by seed-based functional connectivity in these diagnostic areas. For whole-brain functional connectomes from two individuals (100307 and 101006), we selected seeds for networks A and B in TPJ, and confirmed their placement based on functional connectivity patterns observed in TPJ, PCC, DLPFC, and PHC (correlation coefficients thesholded at 0.2), as stipulated by Braga et al. [-@Braga2019]. The whole-brain seed-based functional connectivity maps for two individuals are juxtaposed with the corresponding community detection results in Figure 8. Visual inspection of these networks shows high similarity between our DN community and the previously reported sub-network A. However, the non-DN community filled areas not covered by either DN-A or DN-B. This result supports the idea that the two approaches serve complementary purposes. Whereas Braga and colleagues [-@Braga2017; -@Braga2019] identified subdivisions within the DN, the present community detection approach might be better understood as partitioning DN from non-DN cortex.

## Discussion

A considerable amount of meta-analytic work has been dedicated to characterizing the brain activity patterns associated with psychological processes in medial prefrontal cortex (mPFC), revealing both dissociable and overlapping activation across domains [@DelaVega2016; @Kragel2018; @Hiser2018]. In particular, activation patterns associated with subjective valuation and with the default network (DN) have been suggested to be inseparable in this area, with overlap also partially extending to posterior cingulate cortex (PCC) [@Acikalin2017; @Bartra2013; @Clithero2014; @Laird2009]. This apparent neural overlap has important implications, as it has motivated theoretical proposals about ways in which these superficially dissimilar domains might involve a shared set of core cognitive processes [@Acikalin2017; @Clithero2014; @Northoff2012]. 

However, the interpretation of overlap in group-level data depends on the degree to which functional organization is heterogeneous across individuals. Recent studies have shown that heteromodal brain regions have considerable variability in functional connectivity across individuals [@Mueller2013], individual-specific functional topography can be occluded in aggregative estimations [@Braga2017; @Gordon2017; @Michalka2015; @Tobyne2018], and overlap in functional activation can vanish with increases in spatial precision [@Woo2014]. These findings suggest that group-level and meta-analysis-level overlap does not necessarily imply overlap in individual brains. However, our understanding of the individual-level heterogeneity in the functional topography of mPFC has been mostly descriptive so far [@Braga2017; @Braga2019; @Gordon2017]. To affirm that DN and valuation share neural substrates in this area requires a method to reliably and precisely capture the functional topography of mPFC in isolated individuals, as well as a quantitative estimate of the degree of topographic heterogeneity across a large group of individuals.

Here we address these challenges by using spectral partitioning (SP), a graph-theoretic community detection algorithm that efficiently separates a network into two [@Fiedler1975; @Higham2007; @Toker2019]. For 100 individuals, we subdivided brain regions that typically show overlap between DN and valuation effects into DN and non-DN communities. Restricting our analyses to a general mPFC/PCC search space made it appropriate to use a technique that identified a vertex-wise, binary partitioning that was sensitive to the complex topography of the brain. This contrasts with whole-brain network analyses, which need to allow for multiple sub-networks and which often use parcels that are several orders of magnitude larger than vertices as the units of analysis. Partitioning an individual's brain network through SP has a number of advantages, including identifying communities deterministically, constraining communities to contain a similar number of vertices (i.e. preventing the allocation of most vertices to a single community), providing continuous values that relate to the strength of a node's community affiliation, and the ability to diagnose the connectedness of a network through examination of its resulting eigenvalues [@chung1997; @Higham2007]. Comparisons with partitionings formed by modularity maximization, which heuristically determines the ideal number of communities [@Garcia2017], suggested the binary partitioning was appropriate.

We found a generalizable pattern across individual partitionings, in which the DN community covered ventral/dorsal mPFC and posterior PCC, with the non-DN community concentrated in pregenual ACC and anterior PCC. The precise spatial positioning of this general community structure was highly heterogenous across individuals, yet stable across test/re-test evaluations within-individual. The idiosyncrasy in functional topography was particularly pronounced in mPFC, and was identified in both run-based and day-based analyses. Individual-specificity could theoretically arise from a variety of sources. For example, the functional topography of mPFC could be governed by its underlying sulcal and gyral organization, which has been shown to vary systematically across individuals [@Mackey2014; @Lopez2019]. Individual variability could also be due to shifts in functional organization that are independent of structural features [@Haxby2013], or be characterized by the pattern of functional connections with the rest of the brain [@Mars2018; @Passingham2002; @Tobyne2018]. An important goal for future work will be to assess whether the network layout in this region can be predicted on the basis of aspects of brain structure, such as sulcal morphology, myeloarchitecture [@Glasser2016], or structural connectivity [@Osher2016; @Saygin2011; @Saygin2016]. 

Network-partitioning methods such as SP are data-driven, and therefore provide no labeling information about the resulting communities. We circumvented this issue by independently identifying the DN community based on its coverage of area 7m, a region in PCC that was preferentially associated with the DN relative to subjective valuation in our meta-analysis. We were able to apply labels derived from this group-level approach on the basis of the topography in PCC, where functional organization was more consistent across individuals. Because each community spanned both mPFC and PCC, the labels extended to mPFC where topography was more heterogeneous. 

Our results extend previous work that described individual-specific brain organization. Several recent investigations have identified topographic heterogeneity using a different data aspect ratio than we used here [a small number of individuals and a large number of scanning sessions per individual; @Braga2017; @Braga2019; @Gordon2017]. Previous work has also shown that functional correlations among pre-defined cortical parcels are highly stable within an individual [@Gratton2018b; @Kong2018]. Here we were able to quantify the variability and stability of functional topography in a large sample at a fine, vertex-level spatial granularity, using moderately low amounts of data (down to a single 14 minute scan). The motivation to sub-divide DN also stems from recent work by Kernbach et al. [-@Kernbach2018], which identified specialized communication of parcels within DN with the rest of the brain in a large pool of individuals.
  
In addition to the technical advantages noted above, the SP algorithm offers analytical advantages specific to neuroscience. We found that SP outperformed a traditional seed-based correlation approach in capturing idiosyncratic functional topography. Community detection methods such as SP are stabilized by relying on  all pairwise correlations among cortical vertices (rather than correlations with an individual seed). In addition, we found we could increase the temporal stability of SP results by thresholding the underlying Fiedler vector. The magnitude of Fiedler vector values has been recently used to characterize the continuous connectivity profile of the insula with the rest of the brain, challenging the notion of discrete parcellations in that region [@Tian2018]. The combination of discrete classification and graded information yielded by SP provides additional flexibility and richness relative to some other clustering algorithms. 
  
The community organization of PCC and mPFC was congruent with DN sub-networks A and B proposed by Braga & Buckner [-@Braga2017; @Braga2019]. The topography of our thresholded DN community closely matched network A, whereas our non-DN community included cortical territory that was not part of either DN network. Subthreshold vertices from the DN community overlaped with DN-B vertices, suggesting that this sub-network could act as a dynamic intermediary between DN-A and other networks. Our findings therefore complement the initial identification of DN sub-networks by quantifying the systematic variability of their underlying topography in a larger group of people. Understanding the interaction of networks A (DN), B, and non-DN is an important goal for future research. These two sets of results collectively suggest that canonical DN regions can be topographically partitioned into DN and non-DN communities, and that the DN community can in turn be further divided into sub-networks A and B. 

Our findings show that the functional topography of mPFC is variable across a large pool of individuals, and that the SP algorithm is a useful tool for identifying individualized topography in a data-driven way. The ability to capture an individual's functional topography without the need of group priors is clinically relevant, as it could help characterize heterogenous changes in mPFC activity in disorders such as depression and schizophrenia [@Hiser2018]. It will be beneficial for future task-based fMRI experiments to be able to characterize where task-evoked activity is situated relative to an individual's overall mPFC organization. Our work was originally motivated by the apparent spatial overlap between subjective valuation and the default network [@Acikalin2017], but additional distinctions of interest include valuation versus episodic memory functions [@Euston2012], self-referential thought and theory of mind [@Mitchell2005], and potential topographic distinctions among multiple forms of valuation [@Clithero2014; @Shenhav2019; @Smith2010]. An individualized frame of reference will enhance the ability of future studies to gauge similarities and differences among brain activity patterns associated with diverse psychological domains.

\newpage
## Acknowledgements

We thank Lauren DiNicola, Daniel Reznik, Xavier Guell, and David Somers for helpful discussions, and Daniel Sussman for initial guidance on community detection and evaluation methods. This work was supported by grants from the National Science Foundation (BCS-1755757 and BCS-1625552) and the Office of Naval Research (MURI awards N00014-16-1-2832 and N00014-17-1-2304). Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University.

\newpage

## Figures

```{r Meta-analysis ROIs (Fig. 1), out.width = "50%", fig.align = "center", fig.cap= "Meta-analysis results. A: Proportion of times each ROI was reported in the valuation and DN literatures. B: Regions identified in permutation-based chi-squared tests contrasting the two literatures (see text for details). Areas in blue represent the remainder of the search space."}
# brain images were produced using the HCP wb_view. 
# see the function HCPOut for details on how they were transferred from R to CIFTI
include_graphics("./Images/ROIS.png")
```

\bigskip

```{r Representative partitioning (Fig. 2), out.width = "50%", fig.align = "center", fig.cap = "Brain partition for an example subject (100307). Fiedler vector values (top) are mapped onto the brain surface, dividing it into positive and negative communities. The bottom brain shows the binarized Fiedler vector, with red areas denoting the DN community (as indicated by coverage of area 7m, bordered)."}
include_graphics("./Images/FB_FV_example.png")
```

\bigskip

``` {r Partitioning comparison: all (Fig. 3), fig.align="center", out.width = "50%", fig.cap = "Similarity matrix showing ARI values among all subjects for PCC (lower triangle) and mPFC (upper triangle) separately. Functional topographic patterns were better aligned across individuals in PCC than mPFC.", echo=FALSE, message = FALSE}
# code to produce the plot
# par(xpd = T)
# corrplot(abs(RI_PCC), # absolute for display purposes only, as it avoids the couple of negative ARIs and evens out the color bar
#          is.corr = F, 
#          method = "color",
#          type = "lower", 
#          tl.pos = "n", 
#          tl.cex = 0.1, 
#          cl.lim = c(0,1),
#          cl.length = 3,
#          #addgrid.col = "grey99",
#          cl.pos = "r",
#          mar = c(1,1,2,0))
# corrplot(RI_PFC, 
#          is.corr = F, 
#          method = "color", 
#          type = "upper", 
#          tl.pos = "n", 
#          tl.cex = 0.1,
#          cl.pos = "n",
#          #addgrid.col = "grey90",
#          mar = c(1,1,2,0), 
#          add = T)
# segments(0.5,0.5,0.5,100.5, lwd = 2)
# segments(0.5,0.5,100.5,0.5, lwd = 2)
# segments(0.5,100.5,100.5,100.5, lwd = 2)
# segments(100.5,0.5,100.5,100.5, lwd = 2)
# mtext(expression(bold("Subject Partitions")), line = 3)
# mtext(expression(bold("Subject Partitions")), side = 2, line = -0.8)
# mtext(expression(bold("mPFC")), line = 2, at = par("usr")[1]+0.73*diff(par("usr")[1:2]), col = "steelblue4")
# mtext(expression(bold("PCC")), side = 1, line = 4, at = par("usr")[1]+0.18*diff(par("usr")[1:2]), col = "steelblue4")

include_graphics("./Images/similarity_all.png")

```

\bigskip

``` {r Variability per subject: Fiedler vector vs prop. DN plot (Fig 4), fig.align="center", fig.width=3, fig.height=3, fig.cap = "A: For each individual, we produced partitions for each 20 minute sliding window (84 TRs). B: Proportion of times each vertex was affiliated with the DN community across windows (upper), and the continuous Fiedler vector map for the current subject using their full time series (lower). The maps share considerable qualitative similarities in their gradients along the cortical surface. C: Relationship between the magnitude of Fiedler vector values and the proportion of DN affiliations. Grey lines display data for each subject, and the black line shows the fit from a mixed-effects logistic regression. Dashed red lines indicate the mean FV value at which maps were thresholded. The histogram displays the mean frequency distribution of y-axis values.", echo=FALSE, message = FALSE}
# code to generate plots

# # time series
# # this one uses the actual subject's loaded time series (not included due to space)
# n <- 4 # n of vertices to include
# tr <- 4800 
# ts <- data.matrix(t1[sample(59000, n), 1:tr])
# df <- tibble(vertex = rep(seq(n), each = tr),
#              Time = floor(rep(seq(0, tr, length.out = tr), n)),
#              Signal = matrix(ts, ncol = 1) + rep(seq(-1, 1, length.out = n), each = tr)) %>%
#   ggplot(data = df, aes(Time, Signal, group = vertex, color = as.character(vertex))) +
#     geom_line(show.legend = F, lwd = 0.2, alpha = 0.6) +
#     theme_classic()
# 
# # Fiedler Vector x proportion of times a vertex was affiliated with DN
# SC_FVvPDN_plot <- ggplot(data = allSummaries) +
#   geom_smooth(aes(FiedlerVec, slidePropDN, group = SubjID), color = "gray", fill = "gray", show.legend = F, alpha = 0.3) +
#   geom_line(data = SC_FVvPDN_fits, aes(FiedlerVector, Fitted_Proportion), lwd = 2) +
#   geom_vline(xintercept = c(-0.014, 0.013), linetype = "dashed", color = Cols[2]) +
#   labs(x = "Fiedler Vector Values", y = "Proportion of DN Affiliations") +
#   scale_y_continuous(limits = c(0,1)) +
#   theme_classic()
# 
# SC_FVvPDN_plot
#
# # histogram on 4 C
# hist(allPropDN)

include_graphics("./Images/SW_props.png")

```

\bigskip

```{r Thresholded maps (Fig 5), out.width = "50%", fig.align = "center", fig.cap= "A: Thresholded Fiedler vector maps for subject 100307 (top), and its binarized form (bottom). Subthreshold values effectively formed a third community of high-variability vertices. B: Mean of the binarized maps across all participants, indicating the proportion of DN affiliations per vertex in our sample. Note that 7m-based community label reorientation was used to align the partitionings across individuals in a way that was independent from the community analysis itself. This aggregate map shows the common organizational principle of the DN and non-DN communities, while also showing the high level of variability in mPFC."}

include_graphics("./Images/thresholded.png")

```

\bigskip

``` {r Partition comparison: halves and runs (Fig. 6), fig.align="center", out.width = "100%", fig.cap = "Left: Similarity matrix for 10 example participants (2 scanning days each), showing pattern agreement across days and subjects for PCC and mPFC separately. The block-diagonal structure is indicative of test-retest reliability across days within an individual. Middle: ratio of within-subject ARI to between-subject mean ARI for all individuals across days suggests idiosyncratic community arrangement for both PCC and mPFC (ratios > 1, solid line), with greater subject-specificity in mPFC. Right: within-to-between subject mean ARI ratios for run-specific partitionings again show greater subject-specific organization for mPFC.", echo=FALSE, message = FALSE}
### code for plots in this fig

## similarity matrix
# corrplot(abs(RI_PCC_halves_plot), # absolute to get rid of that annoying -0.02 that messes up the limits. This is just for example.
#          is.corr = F,     
#          method = "color",
#          type = "lower", 
#          tl.pos = "n", 
#          cl.lim = c(0,1),
#          cl.pos = "r",
#          addgrid.col = "grey90",
#          cl.length = 3)
# corrplot(RI_PFC_halves_plot, 
#          is.corr = F, 
#          method = "color",
#          type = "upper", 
#          tl.pos = "n", 
#          cl.pos = "n", 
#          addgrid.col = "grey90",
#          add = T)
#mtext(expression(bold("Subjects (Day 1 and Day 2)")), line = 1)
#mtext(expression(bold("mPFC")), line = -0.15, at = par("usr")[1]+0.8*diff(par("usr")[1:2]), col = "steelblue4")
#mtext(expression(bold("PCC")), side = 1, line = 0.6, at = par("usr")[1]+0.09*diff(par("usr")[1:2]), col = "steelblue4")

# ## ARI for days
# ggplot(data = Halves_RIRatios_summary, aes(Region, RI, fill = Region)) +
#   geom_boxplot(show.legend = F) +
#   scale_fill_manual(values = Cols[seq(2)]) +
#   ylim(0, 20) +
#   geom_hline(yintercept = 1) +
#   labs(y = "ARI Ratio", x = "") +
#   theme_classic(base_size = 14)
# 
# ## ARI for session
# ggplot(data = Sess_RIRatios_summary, aes(Region, RI, fill = Region)) +
#   geom_boxplot(show.legend = F) +
#   scale_fill_manual(values = Cols[seq(2)]) +
#   ylim(0, 20) +
#   geom_hline(yintercept = 1) +
#   labs(y = "ARI Ratio", x = "") +
#   theme_classic(base_size = 14)


include_graphics("./Images/ratios.png")


```

\bigskip

``` {r Correlation vs community detection (Fig. 7), fig.align="center", fig.cap = "A: Correlation matrix comparing the across-day spatial stability of mPFC maps derived from seed-based functional connectivity (using a PCC seed) and the Fiedler vector for 10 example subjects. The top-left quadrant represents seed-based FC maps, and the bottom-right the Fiedler vector, with two single-day-based maps per individual. The upper-right and lower-left quadrants show across-method agreement. B: Day 1 vs Day 2 within-subject correlation coefficients for each method, as well as between methods. Community detection through spectral partitioning provided more stable estimates, even though both methods showed good levels of agreement.", echo = FALSE, message = FALSE}
# code to produce the plots

# correlation matrix
# corrplot(allHalfCombs,
#          #title = "Comparing All Community and Correlation mPFC Partitions \n Across All Subjects",
#          method = "color",
#          #tl.col = "black",
#          #tl.cex = 0.6,
#          addgrid.col = "grey90",
#          tl.pos = "n",
#          cl.pos = "r",
#          cl.length = 3,
#          mar = c(1,2,2,0))
# segments(0.5,0.5,0.5,40.5, lwd = 2)
# segments(0.5,0.5,40.5,0.5, lwd = 2)
# segments(0.5,40.5,40.5,40.5, lwd = 2)
# segments(40.5,0.5,40.5,40.5, lwd = 2)
# segments(0.5,20.5,40.5,20.5, lwd = 2)
# segments(20.5,0.5,20.5,40.5, lwd = 2)
# mtext(expression(bold("Subject Partitions (Day 1 and Day 2)")), line = 3, at = par("usr")[1]+0.45*diff(par("usr")[1:2]))
# mtext(expression(bold("Subject Partitions (Day 1 and Day 2)")), side = 2, line = 3)
# mtext(expression(bold("Fiedler")), line = 1.5, at = par("usr")[1]+0.68*diff(par("usr")[1:2]))
# mtext(expression(bold("Correlation")), line = 1.5, at = par("usr")[1]+0.23*diff(par("usr")[1:2]))
# mtext(expression(bold("Fiedler")), side = 2, line = 2, at = par("usr")[1]+0.25*diff(par("usr")[1:2]))
# mtext(expression(bold("Correlation")), side = 2, line = 2, at = par("usr")[1]+0.68*diff(par("usr")[1:2]))
# 
# # Day 1 vs Day 2 Spatial Correlation Comparison
# prepostComp_plot <- ggplot(data = prepostComp, aes(Approach, Correlation, fill = Approach)) +
#   geom_boxplot(show.legend = F) +
#   labs(x = "", y = "Correlation Coefficient") +
#   ylim(0,1) +
#   theme(text = element_text(size=35)) +
#   theme_classic()
# prepostComp_plot

include_graphics("./Images/commvscorr.png")

```

\bigskip

```{r BandB comparison (Figure 8), out.width = "100%", fig.align = "center", fig.cap= "Qualitative comparison between DN sub-networks A and B from Braga et al. (2019) and SP communities for two individuals. Panel A: Whole-brain networks A and B produced by selecting seeds in TPJ, with our community detection search space delineated by black borders. Correlation values are thresholded at 0.2. Panel B: thresholded communities (indicated by borders) show strong resemblance between the DN community and network A. The non-DN community covers sections of cortex not associated with either DN sub-network."}

# Change to inflated eventually
include_graphics("./Images/braga_comparison.png")

```

\bigskip

\newpage

## Supplemental Materials

\beginsupplement

``` {r Subdivide search space into hemi-region for table, echo = FALSE, message = FALSE} 
# based on a subject's data, create a region vector for PCC and mPFC
# then split by region and hemisphere into a list (length = 4), and retain the unique (and stripped) labels for display
searchSpace <- Summaries[[1]] %>%
                  mutate(region = ifelse(y < 0, "PCC", "mPFC"),
                         Label = str_remove(substr(Label, 3, 20), "_ROI")) %>%
                  select(Hemisphere, region, Label) %>% # unneeded, but makes it easier to examine the df
                  split(list(.$Hemisphere, .$region)) %>%
                  lapply(., function(x) {unique(x$Label)})

```

### *Table 1. Parcels from Glasser et al. (2016) contained in the search space.*
| Hemisphere      |             mPFC             |              PCC            |
| :-------------- | :--------------------------- | :-------------------------- |
| Left            | `r sort(searchSpace$L.mPFC)` | `r sort(searchSpace$L.PCC)` |
| --------------- | ---------------------------- | --------------------------- |
| Right           | `r sort(searchSpace$R.mPFC)` | `r sort(searchSpace$R.PCC)` |
|                 |                              |                             |

\bigskip

```{r Extra examples (supplemental fig 1), out.width = "50%", fig.align = "center", fig.cap = "Additional examples of individualized partitionings, showing both Fiedler vector values (left) and binarized communities (right). A common organizational principle is visible, even though it shifts topographically across individuals."}
include_graphics("./Images/extra_examples.png")
```

\bigskip

```{r ARI Comparison (supplemental fig 2), out.width = "50%", fig.align = "center", fig.cap = "Example of an across-day comparison using ARI for two subjects (100307 and 100408). This reflects how qualitatively similar, within-subject partitionings can have relatively small ARI values (here 0.24-0.25), and how partitionings across individuals are much closer to the chance level of zero."}
include_graphics("./Images/ARI_comparison.png")
```

\newpage 

## References


